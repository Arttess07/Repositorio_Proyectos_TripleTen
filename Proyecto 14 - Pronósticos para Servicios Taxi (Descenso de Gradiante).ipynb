{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hola **Arturo**!\n",
    "\n",
    "Soy **Patricio Requena** üëã. Es un placer ser el revisor de tu proyecto el d√≠a de hoy!\n",
    "\n",
    "Revisar√© tu proyecto detenidamente con el objetivo de ayudarte a mejorar y perfeccionar tus habilidades. Durante mi revisi√≥n, identificar√© √°reas donde puedas hacer mejoras en tu c√≥digo, se√±alando espec√≠ficamente qu√© y c√≥mo podr√≠as ajustar para optimizar el rendimiento y la claridad de tu proyecto. Adem√°s, es importante para m√≠ destacar los aspectos que has manejado excepcionalmente bien. Reconocer tus fortalezas te ayudar√° a entender qu√© t√©cnicas y m√©todos est√°n funcionando a tu favor y c√≥mo puedes aplicarlos en futuras tareas. \n",
    "\n",
    "_**Recuerda que al final de este notebook encontrar√°s un comentario general de mi parte**_, empecemos!\n",
    "\n",
    "Encontrar√°s mis comentarios dentro de cajas verdes, amarillas o rojas, ‚ö†Ô∏è **por favor, no muevas, modifiques o borres mis comentarios** ‚ö†Ô∏è:\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "Si todo est√° perfecto.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "Si tu c√≥digo est√° bien pero se puede mejorar o hay alg√∫n detalle que le hace falta.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Comentario del revisor</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "Si de pronto hace falta algo o existe alg√∫n problema con tu c√≥digo o conclusiones.\n",
    "</div>\n",
    "\n",
    "Puedes responderme de esta forma:\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Respuesta del estudiante</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripci√≥n del proyecto\n",
    "\n",
    "La compa√±√≠a Sweet Lift Taxi ha recopilado datos hist√≥ricos sobre pedidos de taxis en los aeropuertos. Para atraer a m√°s conductores durante las horas pico, necesitamos predecir la cantidad de pedidos de taxis para la pr√≥xima hora. Construye un modelo para dicha predicci√≥n.\n",
    "\n",
    "La m√©trica RECM en el conjunto de prueba no debe ser superior a 48.\n",
    "\n",
    "## Instrucciones del proyecto.\n",
    "\n",
    "1. Descarga los datos y haz el remuestreo por una hora.\n",
    "2. Analiza los datos\n",
    "3. Entrena diferentes modelos con diferentes hiperpar√°metros. La muestra de prueba debe ser el 10% del conjunto de datos inicial.4. Prueba los datos usando la muestra de prueba y proporciona una conclusi√≥n.\n",
    "\n",
    "## Descripci√≥n de los datos\n",
    "\n",
    "Los datos se almacenan en el archivo `taxi.csv`. \t\n",
    "El n√∫mero de pedidos est√° en la columna `num_orders`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "\n",
    "Te felicito por incluir esta secci√≥n introductoria ya que ayuda a entender el que y c√≥mo de tu proyecto antes de revisar cada celda, te animo a mantener esta buena pr√°ctica!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: CatBoost in /opt/conda/envs/python3/lib/python3.9/site-packages (1.0.3)\n",
      "Requirement already satisfied: graphviz in /opt/conda/envs/python3/lib/python3.9/site-packages (from CatBoost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python3/lib/python3.9/site-packages (from CatBoost) (3.3.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/envs/python3/lib/python3.9/site-packages (from CatBoost) (1.21.2)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/conda/envs/python3/lib/python3.9/site-packages (from CatBoost) (1.2.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python3/lib/python3.9/site-packages (from CatBoost) (1.10.1)\n",
      "Requirement already satisfied: plotly in /opt/conda/envs/python3/lib/python3.9/site-packages (from CatBoost) (5.4.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python3/lib/python3.9/site-packages (from CatBoost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python3/lib/python3.9/site-packages (from pandas>=0.24.0->CatBoost) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/python3/lib/python3.9/site-packages (from pandas>=0.24.0->CatBoost) (2024.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python3/lib/python3.9/site-packages (from matplotlib->CatBoost) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python3/lib/python3.9/site-packages (from matplotlib->CatBoost) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/python3/lib/python3.9/site-packages (from matplotlib->CatBoost) (8.4.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/envs/python3/lib/python3.9/site-packages (from matplotlib->CatBoost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/envs/python3/lib/python3.9/site-packages (from plotly->CatBoost) (8.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: LightGBM in /opt/conda/envs/python3/lib/python3.9/site-packages (3.3.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/envs/python3/lib/python3.9/site-packages (from LightGBM) (0.43.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python3/lib/python3.9/site-packages (from LightGBM) (1.21.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python3/lib/python3.9/site-packages (from LightGBM) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/envs/python3/lib/python3.9/site-packages (from LightGBM) (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python3/lib/python3.9/site-packages (from scikit-learn!=0.22.0->LightGBM) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python3/lib/python3.9/site-packages (from scikit-learn!=0.22.0->LightGBM) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "\n",
    "Una buena pr√°ctica para cuando tengas que importar varias librer√≠as es seguir el siguiente √≥rden en las mismas:\n",
    "\n",
    "- Primero todas las librer√≠as que vienen ya con python c√≥mo `datetime`, `os`, `json`, etc.\n",
    "- Luego de las librer√≠as de Python si las de terceros c√≥mo `pandas`, `scipy`, `numpy`, etc.\n",
    "- Por √∫ltimo, en el caso de que armes tu propio m√≥dulo en tu proyecto esto deber√≠a ir en tercer lugar, y recuerda siempre ordenar cada tipo por orden alfab√©tico\n",
    "    \n",
    "Para cada secci√≥n se deben ordenar en orden alfab√©tico\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 26496 entries, 2018-03-01 00:00:00 to 2018-08-31 23:50:00\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   num_orders  26496 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 414.0 KB\n",
      "None\n",
      "\n",
      "                     num_orders\n",
      "datetime                       \n",
      "2018-03-01 00:00:00           9\n",
      "2018-03-01 00:10:00          14\n",
      "2018-03-01 00:20:00          28\n",
      "2018-03-01 00:30:00          20\n",
      "2018-03-01 00:40:00          32\n"
     ]
    }
   ],
   "source": [
    "#Cargamos la data, indicamos que la primera columna con las fechas sea el √≠ndice con \"index_col\" y combertimos la data a tipo datetime con \"parse_dates\"\n",
    "df = pd.read_csv('/datasets/taxi.csv', index_col=[0], parse_dates=[0])\n",
    "print(df.info())\n",
    "print()\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La informaci√≥n de nuetsro dataframe est√° muestreada por cada 10 minutos.\n",
    "Nosotros neceistamos tener esta informaci√≥n por hora, es necesario ajustar los intervalos de muestreo para trabajar con nuestra data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     num_orders\n",
      "datetime                       \n",
      "2018-03-01 00:00:00         124\n",
      "2018-03-01 01:00:00          85\n",
      "2018-03-01 02:00:00          71\n",
      "2018-03-01 03:00:00          66\n",
      "2018-03-01 04:00:00          43\n",
      "2018-03-01 05:00:00           6\n",
      "2018-03-01 06:00:00          12\n",
      "2018-03-01 07:00:00          15\n",
      "2018-03-01 08:00:00          34\n",
      "2018-03-01 09:00:00          69\n",
      "2018-03-01 10:00:00          64\n",
      "2018-03-01 11:00:00          96\n",
      "2018-03-01 12:00:00          30\n",
      "2018-03-01 13:00:00          32\n",
      "2018-03-01 14:00:00          48\n",
      "2018-03-01 15:00:00          66\n",
      "2018-03-01 16:00:00          43\n",
      "2018-03-01 17:00:00          44\n",
      "2018-03-01 18:00:00          73\n",
      "2018-03-01 19:00:00          45\n",
      "2018-03-01 20:00:00          61\n",
      "2018-03-01 21:00:00          66\n",
      "2018-03-01 22:00:00         113\n",
      "2018-03-01 23:00:00          58\n"
     ]
    }
   ],
   "source": [
    "#Aqu√≠ vamos a resamplear los datos para que trabajar con ellos usando intervalos de 1 hora.\n",
    "df.sort_index(inplace=True)\n",
    "df = df.resample('1H').sum()\n",
    "\n",
    "print(df.head(24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora vamos a analizar la data descomponiendola por su tendencia y estacionalidad.\n",
    "decompose_df = seasonal_decompose(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(311)\n",
    "decompose_df.trend.plot(ax=plt.gca())\n",
    "plt.title(\"Tendencias Estacionales\")\n",
    "plt.subplot(312)\n",
    "decompose_df.seasonal.plot(ax=plt.gca())\n",
    "plt.title(\"Estacionalidades\")\n",
    "plt.subplot(313)\n",
    "decompose_df.resid.plot(ax=plt.gca())\n",
    "plt.title(\"Datos Residuales\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el primer gr√°fico anterior podemos observar que la tendencia para el servicio de taxis va en incremento.\n",
    "Conforme pasan los meses crece la demanda por este servicio teniendo un pico en Agosto y Septiembre.\n",
    "En el segundo gr√°fico podemos ver que fluct√∫a la cantidad de servicios de taxis por hora, las horas en las que no hay otro tipo de servicio disponible beneficia a los servicios de Taxis.\n",
    "Horario como altas horas de la noche o madrugadas es cuando m√°s se solicitan los viajes de taxis de este servicio.\n",
    "Los residuos nos muestran informaci√≥n que no es atribuida a estacionalidad ni tendencia.\n",
    "Aqui podemos observar informaci√≥n extra sobre el comportamiento del servicio, teniendo picos en donde crece nuestra tendencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "\n",
    "Muy buen trabajo, realizaste las gr√°ficas correctas para el an√°lisis de datos temporales\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos un an√°lisis de la informaci√≥n y una base de datos transformada a nuestras necesidades. Es tiempo de crear nuestras caracter√≠sticas para entrenar el modelo.\n",
    "Ya que tengamos las caracter√≠sticas vamos a entrenar distintos modelos de regresi√≥n para pronosticar los servicios que se llevaran a cabo la siguiente hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caracteristicas_modelo(data, max_lag, rolling_mean_size):\n",
    "    df['a√±o'] = df.index.year#Primero vamos a agregar las carcater√≠sticas calendario\n",
    "    df['mes'] = df.index.month\n",
    "    df['d√≠a'] = df.index.day\n",
    "    df['d√≠a_semana'] = df.index.dayofweek\n",
    "    df['hora'] = df.index.hour\n",
    "    #Ahora definimos caracter√≠sticas de desfase hacemos esto para encontrar la estacionalidad de la serie\n",
    "    for lag in range(1, max_lag + 1):\n",
    "        df[f'lag_{lag}'] = df['num_orders'].shift(lag)\n",
    "    #Ahora calculamos la m√©dia m√≥vil con el promedio de las series temorales que nos indican su tendencia\n",
    "    df['media_m√≥vil'] = df['num_orders'].shift().rolling(rolling_mean_size).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "\n",
    "Puedes incluir m√°s datos que puedas extraer de la serie temporal c√≥mo la hora por ejemplo para que los modelos tengan m√°s informaci√≥n de donde aprender\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_orders</th>\n",
       "      <th>a√±o</th>\n",
       "      <th>mes</th>\n",
       "      <th>d√≠a</th>\n",
       "      <th>d√≠a_semana</th>\n",
       "      <th>hora</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>media_m√≥vil</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:00:00</th>\n",
       "      <td>124</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 01:00:00</th>\n",
       "      <td>85</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 02:00:00</th>\n",
       "      <td>71</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>85.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 03:00:00</th>\n",
       "      <td>66</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>71.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 04:00:00</th>\n",
       "      <td>43</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 05:00:00</th>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>77.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 06:00:00</th>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>54.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 07:00:00</th>\n",
       "      <td>15</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>39.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 08:00:00</th>\n",
       "      <td>34</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 09:00:00</th>\n",
       "      <td>69</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>34.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     num_orders   a√±o  mes  d√≠a  d√≠a_semana  hora  lag_1  \\\n",
       "datetime                                                                   \n",
       "2018-03-01 00:00:00         124  2018    3    1           3     0    NaN   \n",
       "2018-03-01 01:00:00          85  2018    3    1           3     1  124.0   \n",
       "2018-03-01 02:00:00          71  2018    3    1           3     2   85.0   \n",
       "2018-03-01 03:00:00          66  2018    3    1           3     3   71.0   \n",
       "2018-03-01 04:00:00          43  2018    3    1           3     4   66.0   \n",
       "2018-03-01 05:00:00           6  2018    3    1           3     5   43.0   \n",
       "2018-03-01 06:00:00          12  2018    3    1           3     6    6.0   \n",
       "2018-03-01 07:00:00          15  2018    3    1           3     7   12.0   \n",
       "2018-03-01 08:00:00          34  2018    3    1           3     8   15.0   \n",
       "2018-03-01 09:00:00          69  2018    3    1           3     9   34.0   \n",
       "\n",
       "                     lag_2  lag_3  media_m√≥vil  \n",
       "datetime                                        \n",
       "2018-03-01 00:00:00    NaN    NaN          NaN  \n",
       "2018-03-01 01:00:00    NaN    NaN          NaN  \n",
       "2018-03-01 02:00:00  124.0    NaN          NaN  \n",
       "2018-03-01 03:00:00   85.0  124.0          NaN  \n",
       "2018-03-01 04:00:00   71.0   85.0          NaN  \n",
       "2018-03-01 05:00:00   66.0   71.0         77.8  \n",
       "2018-03-01 06:00:00   43.0   66.0         54.2  \n",
       "2018-03-01 07:00:00    6.0   43.0         39.6  \n",
       "2018-03-01 08:00:00   12.0    6.0         28.4  \n",
       "2018-03-01 09:00:00   15.0   12.0         22.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sacamos las caracter√≠sticas de nuestro dataframe para entrenar el modelo.\n",
    "#Definimos un lag de 3 horas para tener series temporales que anlizen el comportamiento en este intervalo.\n",
    "#Creamos una media movil de las √∫ltimas 5 horas para pronosticar el comportamiento cada 5 horas.\n",
    "caracteristicas_modelo(df, 3, 5)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora vamos a dividir la data en sets de entrenamiento y de prueba\n",
    "#Nos aseguramos que los datos sigan un √≥rden cronol√≥gico usando \"shuffle=False\"\n",
    "train, test = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "train = train.dropna()\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos nuestros datasets de entrenamiento y prueba\n",
    "feat_train = train.drop(['num_orders'], axis=1)\n",
    "target_train = train['num_orders']\n",
    "\n",
    "feat_test = test.drop(['num_orders'], axis=1)\n",
    "target_test = test['num_orders']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "\n",
    "Muy bien, dividiste los datos en los sets necesarios para la parte de entrenamiento y pruebas\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(valid, predict): #Definimos nuestra m√©trica de error\n",
    "    return math.sqrt(mean_squared_error(valid, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de √°rboles: 1\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  -0.002727091841222107\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 58.62939008043759\n",
      "Cantidad de √°rboles: 2\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.0633636288047621\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 56.664297752743096\n",
      "Cantidad de √°rboles: 3\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.05986603002438173\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 56.76999741887408\n",
      "Cantidad de √°rboles: 4\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.06185428548796035\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 56.709935235064414\n",
      "Cantidad de √°rboles: 5\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.05786535673460469\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 56.83037065272166\n",
      "Cantidad de √°rboles: 6\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.08428730616154712\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 56.02780636698813\n",
      "Cantidad de √°rboles: 7\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.07848517472134708\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 56.20502755249874\n",
      "Cantidad de √°rboles: 8\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.08298463350182195\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 56.06764416406504\n",
      "Cantidad de √°rboles: 9\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.07620845853267821\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 56.2744154522131\n",
      "Cantidad de √°rboles: 10\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.06584635696399843\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 56.589148312843086\n",
      "Cantidad de √°rboles: 11\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.07827264958618385\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 56.21150834484405\n",
      "Cantidad de √°rboles: 12\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.09779997101372129\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.612884336852495\n",
      "Cantidad de √°rboles: 13\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.09533129567064724\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.68891867733947\n",
      "Cantidad de √°rboles: 14\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.10158968027850912\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.49595990535922\n",
      "Cantidad de √°rboles: 15\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.09650750490612714\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.652704798919245\n",
      "Cantidad de √°rboles: 16\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.1010135849052094\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.51375012961694\n",
      "Cantidad de √°rboles: 17\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.10390796509869982\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.424311938697\n",
      "Cantidad de √°rboles: 18\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.09933788373042207\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.565464563756976\n",
      "Cantidad de √°rboles: 19\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.10742309815636697\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.31549763179249\n",
      "Cantidad de √°rboles: 20\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.10384544015033959\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.42624552456724\n",
      "Cantidad de √°rboles: 21\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.10115920294049097\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.50925388224887\n",
      "Cantidad de √°rboles: 22\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.10522622865263465\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.38352888356131\n",
      "Cantidad de √°rboles: 23\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.09937536012482417\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.56430851706091\n",
      "Cantidad de √°rboles: 24\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.09688133280219857\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.641190211848375\n",
      "Cantidad de √°rboles: 25\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.09650017367070152\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.652930590641645\n",
      "Cantidad de √°rboles: 26\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.10145206075014934\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.50021021015266\n",
      "Cantidad de √°rboles: 27\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.09460867298861053\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.71115557065955\n",
      "Cantidad de √°rboles: 28\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.09822731638555349\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.599711690576704\n",
      "Cantidad de √°rboles: 29\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.0954434890442658\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.685465412430226\n",
      "Cantidad de √°rboles: 30\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.09261831247436936\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.772358062261844\n",
      "Cantidad de √°rboles: 31\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.10061138383541413\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.5261669985239\n",
      "Cantidad de √°rboles: 32\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.103618540381327\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.43326184012282\n",
      "Cantidad de √°rboles: 33\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.10795883396547479\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.29889461366488\n",
      "Cantidad de √°rboles: 34\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11494912966124693\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.08179930893433\n",
      "Cantidad de √°rboles: 35\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11733635107857299\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.00746389902877\n",
      "Cantidad de √°rboles: 36\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.12365380815479621\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.81025892289351\n",
      "Cantidad de √°rboles: 37\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.12482894251291443\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.77349775137195\n",
      "Cantidad de √°rboles: 38\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.12383225117419416\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.8046783623122\n",
      "Cantidad de √°rboles: 39\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.12525458620766894\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.7601764531148\n",
      "Cantidad de √°rboles: 40\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.1244700596385806\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.78472713066458\n",
      "Cantidad de √°rboles: 41\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.1253298796678488\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.75781966917097\n",
      "Cantidad de √°rboles: 42\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.1249328219190059\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.77024695416051\n",
      "Cantidad de √°rboles: 43\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.12318074004844681\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.82505072968428\n",
      "Cantidad de √°rboles: 44\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.12010921306722411\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.92099376677762\n",
      "Cantidad de √°rboles: 45\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11808733678047312\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.98405826232\n",
      "Cantidad de √°rboles: 46\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11884948537831574\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.96029452563549\n",
      "Cantidad de √°rboles: 47\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11839272835299242\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.974537409158096\n",
      "Cantidad de √°rboles: 48\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11939745693155401\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.943202461811836\n",
      "Cantidad de √°rboles: 49\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11744415777310357\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.00410454807413\n",
      "Cantidad de √°rboles: 50\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11834852207932633\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.97591568101439\n",
      "Cantidad de √°rboles: 51\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11960929938427944\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.93659334913714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de √°rboles: 52\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.12055166600777356\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.90718352400297\n",
      "Cantidad de √°rboles: 53\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.12131345948016314\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.88339759234253\n",
      "Cantidad de √°rboles: 54\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11988443748173327\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.92800833631928\n",
      "Cantidad de √°rboles: 55\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.12000867636615031\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.92413132538126\n",
      "Cantidad de √°rboles: 56\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11907625455374804\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.95322189590704\n",
      "Cantidad de √°rboles: 57\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11806060122009943\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.98489168864983\n",
      "Cantidad de √°rboles: 58\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11725750409544666\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.009920710142076\n",
      "Cantidad de √°rboles: 59\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11859030108056545\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.968377025590314\n"
     ]
    }
   ],
   "source": [
    "#Empecemos con el modelo RandomForestRegressor\n",
    "for trees in range(1, 60):\n",
    "    forest_model = RandomForestRegressor(n_estimators=trees, max_depth=7, max_leaf_nodes=20, random_state=12345)\n",
    "    forest_model.fit(feat_train, target_train)\n",
    "    forest_predict = forest_model.predict(feat_test)\n",
    "    print(\"Cantidad de √°rboles:\", trees)\n",
    "    print()\n",
    "    print(\"Valuaci√≥n de dataset de prueba en RandomForestRegressor: \", forest_model.score(feat_test, target_test))\n",
    "    print()\n",
    "    print(f\"RMSE RandomForestRegressor model prueba: {rmse(forest_predict, target_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profundidad de √°rbol: 4\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.039215236835613454\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 57.39010975802464\n",
      "Profundidad de √°rbol: 5\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11770766598449967\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.995892537818115\n",
      "Profundidad de √°rbol: 6\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.12733133861865398\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.69513415326901\n",
      "Profundidad de √°rbol: 7\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.12525458620766894\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.7601764531148\n",
      "Profundidad de √°rbol: 8\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11740756175026679\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.005244935176705\n",
      "Profundidad de √°rbol: 9\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11740756175026679\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.005244935176705\n"
     ]
    }
   ],
   "source": [
    "for depth in range(4, 10):\n",
    "    forest_model = RandomForestRegressor(n_estimators=39, max_depth=depth, max_leaf_nodes=20, random_state=12345)\n",
    "    forest_model.fit(feat_train, target_train)\n",
    "    forest_predict = forest_model.predict(feat_test)\n",
    "    print(\"Profundidad de √°rbol:\", depth)\n",
    "    print()\n",
    "    print(\"Valuaci√≥n de dataset de prueba en RandomForestRegressor: \", forest_model.score(feat_test, target_test))\n",
    "    print()\n",
    "    print(f\"RMSE RandomForestRegressor model prueba: {rmse(forest_predict, target_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de nodos: 10\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.02828481002098293\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 57.715637582214605\n",
      "Cantidad de nodos: 11\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.042932146310713515\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 57.27899197264268\n",
      "Cantidad de nodos: 12\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.06032103583491932\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 56.756257991487786\n",
      "Cantidad de nodos: 13\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.0748167764212424\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 56.31678790335994\n",
      "Cantidad de nodos: 14\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.08431545764275516\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 56.02694513732996\n",
      "Cantidad de nodos: 15\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.0934244609410454\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.74757753596064\n",
      "Cantidad de nodos: 16\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.09597566288427917\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.66908240730715\n",
      "Cantidad de nodos: 17\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.1055692561851872\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 55.37291173259673\n",
      "Cantidad de nodos: 18\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.11891203539141915\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.95834376461518\n",
      "Cantidad de nodos: 19\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.12159683180450098\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.874547058434615\n",
      "Cantidad de nodos: 20\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.12733133861865398\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.69513415326901\n",
      "Cantidad de nodos: 21\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.12565313993734184\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.74770004640192\n",
      "Cantidad de nodos: 22\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.12948404069103148\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.62763142551668\n",
      "Cantidad de nodos: 23\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.13450966225055894\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.46971634976537\n",
      "Cantidad de nodos: 24\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.14235135405063148\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.2223960617139\n",
      "Cantidad de nodos: 25\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.14629649751745188\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 54.09754207873167\n",
      "Cantidad de nodos: 26\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.14963403964547095\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.99169172308926\n",
      "Cantidad de nodos: 27\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.15429447094786597\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.84353770055368\n",
      "Cantidad de nodos: 28\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.15219707548931094\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.9102637981099\n",
      "Cantidad de nodos: 29\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.15427739737360047\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.84408120947509\n",
      "Cantidad de nodos: 30\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.15449334281060478\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.83720654044363\n",
      "Cantidad de nodos: 31\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.15600260634508178\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.78913428400804\n",
      "Cantidad de nodos: 32\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.1565613158036825\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.771327669019655\n",
      "Cantidad de nodos: 33\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.15689828265814576\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.76058535569739\n",
      "Cantidad de nodos: 34\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.15616447360917218\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.78397602311375\n",
      "Cantidad de nodos: 35\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.1569106655271968\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.76019055592456\n",
      "Cantidad de nodos: 36\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.1593311610165633\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.68296277866108\n",
      "Cantidad de nodos: 37\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.15976845431838416\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.66899874636779\n",
      "Cantidad de nodos: 38\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.1610363278264384\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.62849134642054\n",
      "Cantidad de nodos: 39\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.1610024915473074\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.62957278198626\n",
      "Cantidad de nodos: 40\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.16075483835229298\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.6374873198454\n",
      "Cantidad de nodos: 41\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.1603930695930028\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.64904668142598\n",
      "Cantidad de nodos: 42\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.15865360199848733\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.70459201469033\n",
      "Cantidad de nodos: 43\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.15902092553003655\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.69286728747613\n",
      "Cantidad de nodos: 44\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.1588935768774351\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.696932463217955\n",
      "Cantidad de nodos: 45\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.1591931389430843\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.687369466165144\n",
      "Cantidad de nodos: 46\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.15887344693604177\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.69757501546018\n",
      "Cantidad de nodos: 47\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.15846237040469124\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.71069498918568\n",
      "Cantidad de nodos: 48\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.1577988933464618\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.73186385407621\n",
      "Cantidad de nodos: 49\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en RandomForestRegressor:  0.15630238500883142\n",
      "\n",
      "RMSE RandomForestRegressor model prueba: 53.779580778856946\n"
     ]
    }
   ],
   "source": [
    "for leaves in range(10, 50):\n",
    "    forest_model = RandomForestRegressor(n_estimators=39, max_depth=6, max_leaf_nodes=leaves, random_state=12345)\n",
    "    forest_model.fit(feat_train, target_train)\n",
    "    forest_predict = forest_model.predict(feat_test)\n",
    "    print(\"Cantidad de nodos:\", leaves)\n",
    "    print()\n",
    "    print(\"Valuaci√≥n de dataset de prueba en RandomForestRegressor: \", forest_model.score(feat_test, target_test))\n",
    "    print()\n",
    "    print(f\"RMSE RandomForestRegressor model prueba: {rmse(forest_predict, target_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones modelo RandomForestRegressor\n",
    "\n",
    "Este modelo por m√°s que lo iteramos no llegamos a minimizar el error con un valor menor al objetivo deseado.\n",
    "Tendr√≠amos que usar mucho recursos para que esto suceda y no creo que sea ideal para nuestra problem√°tica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 1\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  -0.9286976151616717\n",
      "\n",
      "RMSE LightGBM model prueba: 81.31226776541365\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 2\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  -0.7785565890793191\n",
      "\n",
      "RMSE LightGBM model prueba: 78.08324359554231\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 3\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  -0.661606744684959\n",
      "\n",
      "RMSE LightGBM model prueba: 75.47239380236304\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 4\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  -0.5506102851656396\n",
      "\n",
      "RMSE LightGBM model prueba: 72.90802468423261\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 5\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  -0.46229808317865806\n",
      "\n",
      "RMSE LightGBM model prueba: 70.80141822544064\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 6\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  -0.38280085301817124\n",
      "\n",
      "RMSE LightGBM model prueba: 68.84998043450003\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 7\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  -0.31135904665567726\n",
      "\n",
      "RMSE LightGBM model prueba: 67.04784291010562\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 8\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  -0.25209673016376777\n",
      "\n",
      "RMSE LightGBM model prueba: 65.51533144612732\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 9\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  -0.20130386868715777\n",
      "\n",
      "RMSE LightGBM model prueba: 64.17271883421367\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 10\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  -0.14696876200391618\n",
      "\n",
      "RMSE LightGBM model prueba: 62.70465702835474\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 11\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  -0.106296388484447\n",
      "\n",
      "RMSE LightGBM model prueba: 61.58284508070499\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valuaci√≥n de dataset de prueba en light_model:  -0.06202107215064556\n",
      "\n",
      "RMSE LightGBM model prueba: 60.33795249235701\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 13\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  -0.021288898964428205\n",
      "\n",
      "RMSE LightGBM model prueba: 59.1695555966822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 14\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.018521823398158554\n",
      "\n",
      "RMSE LightGBM model prueba: 58.004852329513746\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 15\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.047914241711015215\n",
      "\n",
      "RMSE LightGBM model prueba: 57.12971219608972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 16\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.07396463564078193\n",
      "\n",
      "RMSE LightGBM model prueba: 56.34271724643038\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 17\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.09687256956584644\n",
      "\n",
      "RMSE LightGBM model prueba: 55.641460162927686\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 18\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.12917357865667878\n",
      "\n",
      "RMSE LightGBM model prueba: 54.63737179473694\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de iteraciones: 19\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.1563227800834036\n",
      "\n",
      "RMSE LightGBM model prueba: 53.77893075616538\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 20\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.17202045406001631\n",
      "\n",
      "RMSE LightGBM model prueba: 53.276269350938804\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 21\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.19711596763080674\n",
      "\n",
      "RMSE LightGBM model prueba: 52.46267274093377\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 22\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.20336896779895586\n",
      "\n",
      "RMSE LightGBM model prueba: 52.25797921517016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 23\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.2379610442856781\n",
      "\n",
      "RMSE LightGBM model prueba: 51.1107893713529\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 24\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.2527666471994614\n",
      "\n",
      "RMSE LightGBM model prueba: 50.61183994949752\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 25\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valuaci√≥n de dataset de prueba en light_model:  0.2802177178367471\n",
      "\n",
      "RMSE LightGBM model prueba: 49.67347898956846\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 26\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.2927973578982562\n",
      "\n",
      "RMSE LightGBM model prueba: 49.237493791127235\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 27\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.2985401937485799\n",
      "\n",
      "RMSE LightGBM model prueba: 49.03716985714326\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de iteraciones: 28\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.3063910270854121\n",
      "\n",
      "RMSE LightGBM model prueba: 48.761982377062395\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 29\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.3126981404072965\n",
      "\n",
      "RMSE LightGBM model prueba: 48.53977526636848\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valuaci√≥n de dataset de prueba en light_model:  0.32289715157570653\n",
      "\n",
      "RMSE LightGBM model prueba: 48.17828342493435\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 31\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.3262769856468061\n",
      "\n",
      "RMSE LightGBM model prueba: 48.05788937056102\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valuaci√≥n de dataset de prueba en light_model:  0.3297214511389963\n",
      "\n",
      "RMSE LightGBM model prueba: 47.93488194992417\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 33\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.3425287589587577\n",
      "\n",
      "RMSE LightGBM model prueba: 47.47471673913024\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 34\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.3495502973703738\n",
      "\n",
      "RMSE LightGBM model prueba: 47.22053046370873\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 35\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.36859982053776474\n",
      "\n",
      "RMSE LightGBM model prueba: 46.52392557264716\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 36\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.37258319734781586\n",
      "\n",
      "RMSE LightGBM model prueba: 46.37693833044003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 37\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.3768913738765306\n",
      "\n",
      "RMSE LightGBM model prueba: 46.217439730602585\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 38\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.3814239221368516\n",
      "\n",
      "RMSE LightGBM model prueba: 46.049038020006776\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de iteraciones: 39\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.3872682910598846\n",
      "\n",
      "RMSE LightGBM model prueba: 45.8309837795267\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 40\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.3893184634619251\n",
      "\n",
      "RMSE LightGBM model prueba: 45.754245342331785\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de iteraciones: 41\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.3891744986210307\n",
      "\n",
      "RMSE LightGBM model prueba: 45.75963818138957\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 42\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.3910644651580706\n",
      "\n",
      "RMSE LightGBM model prueba: 45.68879046261281\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de iteraciones: 43\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.39429070168492764\n",
      "\n",
      "RMSE LightGBM model prueba: 45.56759651348204\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 44\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.3958047432245748\n",
      "\n",
      "RMSE LightGBM model prueba: 45.51061010014326\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de iteraciones: 45\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.40609261929753737\n",
      "\n",
      "RMSE LightGBM model prueba: 45.121482783864955\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 46\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4080822283603336\n",
      "\n",
      "RMSE LightGBM model prueba: 45.045840161172606\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de iteraciones: 47\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.40949216826569546\n",
      "\n",
      "RMSE LightGBM model prueba: 44.992158892504285\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 48\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4178743226624634\n",
      "\n",
      "RMSE LightGBM model prueba: 44.67168970166759\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 49\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4187872463596587\n",
      "\n",
      "RMSE LightGBM model prueba: 44.636647572981566\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de iteraciones: 50\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4195453115390373\n",
      "\n",
      "RMSE LightGBM model prueba: 44.607528692981994\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 51\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.41966769160081685\n",
      "\n",
      "RMSE LightGBM model prueba: 44.60282603487898\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de iteraciones: 52\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4209351586997243\n",
      "\n",
      "RMSE LightGBM model prueba: 44.55409230527286\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 53\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4228835722876192\n",
      "\n",
      "RMSE LightGBM model prueba: 44.479072256333076\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de iteraciones: 54\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.42256199260081795\n",
      "\n",
      "RMSE LightGBM model prueba: 44.4914628013274\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 55\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.43357585968814416\n",
      "\n",
      "RMSE LightGBM model prueba: 44.06511205849782\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de iteraciones: 56\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4331040406032374\n",
      "\n",
      "RMSE LightGBM model prueba: 44.08346088193851\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 57\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4320534659884232\n",
      "\n",
      "RMSE LightGBM model prueba: 44.12428982697594\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de iteraciones: 58\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.43385430739576136\n",
      "\n",
      "RMSE LightGBM model prueba: 44.0542797714682\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 59\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4328023971845669\n",
      "\n",
      "RMSE LightGBM model prueba: 44.09518765226605\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de iteraciones: 60\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4392149604336216\n",
      "\n",
      "RMSE LightGBM model prueba: 43.845215740396995\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de iteraciones: 61\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4398095649356307\n",
      "\n",
      "RMSE LightGBM model prueba: 43.82196487313111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de iteraciones: 62\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4393976165539082\n",
      "\n",
      "RMSE LightGBM model prueba: 43.8380746358101\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de iteraciones: 63\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.44024056284264224\n",
      "\n",
      "RMSE LightGBM model prueba: 43.80510381285677\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de iteraciones: 64\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4387527350127145\n",
      "\n",
      "RMSE LightGBM model prueba: 43.86328166358172\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de iteraciones: 65\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.43744171664167064\n",
      "\n",
      "RMSE LightGBM model prueba: 43.91448193571535\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de iteraciones: 66\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4370583129595359\n",
      "\n",
      "RMSE LightGBM model prueba: 43.92944403546364\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de iteraciones: 67\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4396954871428441\n",
      "\n",
      "RMSE LightGBM model prueba: 43.82642662241769\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de iteraciones: 68\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4377399514879775\n",
      "\n",
      "RMSE LightGBM model prueba: 43.90283997308869\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de iteraciones: 69\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4364512329901393\n",
      "\n",
      "RMSE LightGBM model prueba: 43.95312455167674\n"
     ]
    }
   ],
   "source": [
    "#Ahora veamos como itera el modelo LightGBM\n",
    "for iteration in range (1, 70):\n",
    "    light_model = LGBMRegressor(num_iterations=iteration, num_leaves=25, max_depth=10, verbose=1, metric='rmse', random_state=12345)\n",
    "    light_model.fit(feat_train, target_train)\n",
    "    light_predict = light_model.predict(feat_test)\n",
    "    print(\"N√∫mero de iteraciones:\", iteration)\n",
    "    print()\n",
    "    print(\"Valuaci√≥n de dataset de prueba en light_model: \", light_model.score(feat_test, target_test))\n",
    "    print()\n",
    "    print(f\"RMSE LightGBM model prueba: {rmse(light_predict, target_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de nodos: 10\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.40611179987505375\n",
      "\n",
      "RMSE LightGBM model prueba: 45.12075416597434\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de nodos: 11\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.39198711604986536\n",
      "\n",
      "RMSE LightGBM model prueba: 45.654163822305044\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de nodos: 12\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.41632893810386584\n",
      "\n",
      "RMSE LightGBM model prueba: 44.73094596337268\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de nodos: 13\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.42490413853173525\n",
      "\n",
      "RMSE LightGBM model prueba: 44.40114022208022\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de nodos: 14\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.418336878709726\n",
      "\n",
      "RMSE LightGBM model prueba: 44.65393815129203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de nodos: 15\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.42190684026778624\n",
      "\n",
      "RMSE LightGBM model prueba: 44.51669531291707\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de nodos: 16\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.43556045322521886\n",
      "\n",
      "RMSE LightGBM model prueba: 43.987848338445595\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de nodos: 17\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.41556447184555834\n",
      "\n",
      "RMSE LightGBM model prueba: 44.76022967433681\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de nodos: 18\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.431910489724596\n",
      "\n",
      "RMSE LightGBM model prueba: 44.12984345635134\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de nodos: 19\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.43697806662623595\n",
      "\n",
      "RMSE LightGBM model prueba: 43.93257495583332\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de nodos: 20\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.41198492167019685\n",
      "\n",
      "RMSE LightGBM model prueba: 44.89709413380803\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de nodos: 21\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.43691929701899457\n",
      "\n",
      "RMSE LightGBM model prueba: 43.934867790845125\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de nodos: 22\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4503555817998909\n",
      "\n",
      "RMSE LightGBM model prueba: 43.40751387704431\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de nodos: 23\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.45569332486083136\n",
      "\n",
      "RMSE LightGBM model prueba: 43.196228710688494\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de nodos: 24\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4317968081587644\n",
      "\n",
      "RMSE LightGBM model prueba: 44.13425869256003\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de nodos: 25\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4392149604336216\n",
      "\n",
      "RMSE LightGBM model prueba: 43.845215740396995\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de nodos: 26\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.429471925810752\n",
      "\n",
      "RMSE LightGBM model prueba: 44.22445724913849\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de nodos: 27\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.43714882266953814\n",
      "\n",
      "RMSE LightGBM model prueba: 43.925912407622356\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "N√∫mero de nodos: 28\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.46056560732675156\n",
      "\n",
      "RMSE LightGBM model prueba: 43.00246172027417\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 29\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.40451023033272127\n",
      "\n",
      "RMSE LightGBM model prueba: 45.18155295909425\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 30\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4339740447792735\n",
      "\n",
      "RMSE LightGBM model prueba: 44.04962087959834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 31\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.42845324026099785\n",
      "\n",
      "RMSE LightGBM model prueba: 44.2639213226928\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 32\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.41097213427340273\n",
      "\n",
      "RMSE LightGBM model prueba: 44.93574250346356\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 33\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.42127347499925916\n",
      "\n",
      "RMSE LightGBM model prueba: 44.54107512926272\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 34\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4393217666443575\n",
      "\n",
      "RMSE LightGBM model prueba: 43.841040197168034\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 35\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.43045936077341396\n",
      "\n",
      "RMSE LightGBM model prueba: 44.18617018803976\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de nodos: 36\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.42465635220124276\n",
      "\n",
      "RMSE LightGBM model prueba: 44.410704549973296\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 37\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4597481689625982\n",
      "\n",
      "RMSE LightGBM model prueba: 43.03503153374195\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 38\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.399346398091343\n",
      "\n",
      "RMSE LightGBM model prueba: 45.377027643899865\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 39\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4410720123416262\n",
      "\n",
      "RMSE LightGBM model prueba: 43.772558344049656\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valuaci√≥n de dataset de prueba en light_model:  0.4221464938953716\n",
      "\n",
      "RMSE LightGBM model prueba: 44.507466961691335\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 41\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.3983625692635716\n",
      "\n",
      "RMSE LightGBM model prueba: 45.41417464685055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 42\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.40955008474701926\n",
      "\n",
      "RMSE LightGBM model prueba: 44.98995244299876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 43\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4291647226131853\n",
      "\n",
      "RMSE LightGBM model prueba: 44.23636206762075\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 44\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4347050277783784\n",
      "\n",
      "RMSE LightGBM model prueba: 44.02116818563587\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 45\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.450810016529241\n",
      "\n",
      "RMSE LightGBM model prueba: 43.38956594553429\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 46\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4097403364425629\n",
      "\n",
      "RMSE LightGBM model prueba: 44.98270364499135\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 47\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4223300170855683\n",
      "\n",
      "RMSE LightGBM model prueba: 44.50039873342804\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 48\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.40461265352670484\n",
      "\n",
      "RMSE LightGBM model prueba: 45.17766721814411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "N√∫mero de nodos: 49\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.40233300152196005\n",
      "\n",
      "RMSE LightGBM model prueba: 45.26407396300783\n"
     ]
    }
   ],
   "source": [
    "for leaves in range (10, 50):\n",
    "    light_model = LGBMRegressor(num_iterations=60, num_leaves=leaves, max_depth=10, verbose=1, metric='rmse', random_state=12345)\n",
    "    light_model.fit(feat_train, target_train)\n",
    "    light_predict = light_model.predict(feat_test)\n",
    "    print(\"N√∫mero de nodos:\", leaves)\n",
    "    print()\n",
    "    print(\"Valuaci√≥n de dataset de prueba en light_model: \", light_model.score(feat_test, target_test))\n",
    "    print()\n",
    "    print(f\"RMSE LightGBM model prueba: {rmse(light_predict, target_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Profundidad m√°xima: 4\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4116371561441966\n",
      "\n",
      "RMSE LightGBM model prueba: 44.91036875400588\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Profundidad m√°xima: 5\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.44533291196878977\n",
      "\n",
      "RMSE LightGBM model prueba: 43.60539253614652\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Profundidad m√°xima: 6\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.44335471216214184\n",
      "\n",
      "RMSE LightGBM model prueba: 43.683081844605674\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profundidad m√°xima: 7\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.4317640955859898\n",
      "\n",
      "RMSE LightGBM model prueba: 44.135529122215175\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Profundidad m√°xima: 8\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.42729631440763294\n",
      "\n",
      "RMSE LightGBM model prueba: 44.30869822448961\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Profundidad m√°xima: 9\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.44977443948645324\n",
      "\n",
      "RMSE LightGBM model prueba: 43.43045532594997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "for depth in range (4, 10):\n",
    "    light_model = LGBMRegressor(num_iterations=60, num_leaves=45, max_depth=depth, verbose=1, metric='rmse', random_state=12345)\n",
    "    light_model.fit(feat_train, target_train)\n",
    "    light_predict = light_model.predict(feat_test)\n",
    "    print(\"Profundidad m√°xima:\", depth)\n",
    "    print()\n",
    "    print(\"Valuaci√≥n de dataset de prueba en light_model: \", light_model.score(feat_test, target_test))\n",
    "    print()\n",
    "    print(f\"RMSE LightGBM model prueba: {rmse(light_predict, target_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 895\n",
      "[LightGBM] [Info] Number of data points in the train set: 3969, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 78.291257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en light_model:  0.44977443948645324\n",
      "\n",
      "RMSE LightGBM model prueba: 43.43045532594997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "light_model = LGBMRegressor(num_iterations=60, num_leaves=45, max_depth=9, verbose=1, metric='rmse', random_state=12345)\n",
    "light_model.fit(feat_train, target_train)\n",
    "light_predict = light_model.predict(feat_test)\n",
    "print()\n",
    "print(\"Valuaci√≥n de dataset de prueba en light_model: \", light_model.score(feat_test, target_test))\n",
    "print()\n",
    "print(f\"RMSE LightGBM model prueba: {rmse(light_predict, target_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n Modelo LightGBM\n",
    "\n",
    "Hemos iterado nuetro modelo y llegamos a la conclusi√≥n que la mejor manera de entrenarlo es la siguiente:\n",
    "\n",
    "Fijar el n√∫mero de iteraciones a 60, el m√°ximo de nodos que sea 45 y m√°xima profundidad del √°rbol en 9.\n",
    "\n",
    "Con esta combinaci√≥n en los hiperpar√°metros pudimos alcanzar un error m√≠nimo del 43.43 con el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 32.1081976\ttotal: 2.2ms\tremaining: 130ms\n",
      "1:\tlearn: 28.2555847\ttotal: 3.96ms\tremaining: 115ms\n",
      "2:\tlearn: 26.2832391\ttotal: 5.47ms\tremaining: 104ms\n",
      "3:\tlearn: 25.0724734\ttotal: 7.02ms\tremaining: 98.3ms\n",
      "4:\tlearn: 24.1793293\ttotal: 8.56ms\tremaining: 94.2ms\n",
      "5:\tlearn: 23.5944209\ttotal: 10ms\tremaining: 90.2ms\n",
      "6:\tlearn: 23.2351080\ttotal: 11.5ms\tremaining: 87.2ms\n",
      "7:\tlearn: 22.9306457\ttotal: 12.9ms\tremaining: 84.2ms\n",
      "8:\tlearn: 22.6633001\ttotal: 14.5ms\tremaining: 82.3ms\n",
      "9:\tlearn: 22.4973205\ttotal: 16ms\tremaining: 79.8ms\n",
      "10:\tlearn: 22.0068204\ttotal: 17.4ms\tremaining: 77.6ms\n",
      "11:\tlearn: 21.9672251\ttotal: 18.9ms\tremaining: 75.6ms\n",
      "12:\tlearn: 21.7536910\ttotal: 20.5ms\tremaining: 74ms\n",
      "13:\tlearn: 21.4333996\ttotal: 22ms\tremaining: 72.4ms\n",
      "14:\tlearn: 21.2340231\ttotal: 23.5ms\tremaining: 70.4ms\n",
      "15:\tlearn: 20.9778467\ttotal: 24.9ms\tremaining: 68.6ms\n",
      "16:\tlearn: 20.7822810\ttotal: 26.5ms\tremaining: 67ms\n",
      "17:\tlearn: 20.6414963\ttotal: 27.9ms\tremaining: 65.1ms\n",
      "18:\tlearn: 20.5212220\ttotal: 29.4ms\tremaining: 63.5ms\n",
      "19:\tlearn: 20.2590320\ttotal: 31ms\tremaining: 61.9ms\n",
      "20:\tlearn: 20.0525890\ttotal: 32.5ms\tremaining: 60.3ms\n",
      "21:\tlearn: 19.8215413\ttotal: 34ms\tremaining: 58.7ms\n",
      "22:\tlearn: 19.6677800\ttotal: 35.6ms\tremaining: 57.3ms\n",
      "23:\tlearn: 19.5844846\ttotal: 37ms\tremaining: 55.5ms\n",
      "24:\tlearn: 19.3242596\ttotal: 38.6ms\tremaining: 54ms\n",
      "25:\tlearn: 19.3066212\ttotal: 40ms\tremaining: 52.3ms\n",
      "26:\tlearn: 19.1297655\ttotal: 41.5ms\tremaining: 50.7ms\n",
      "27:\tlearn: 19.1035083\ttotal: 42.9ms\tremaining: 49ms\n",
      "28:\tlearn: 18.9806280\ttotal: 44.4ms\tremaining: 47.5ms\n",
      "29:\tlearn: 18.8310632\ttotal: 45.9ms\tremaining: 45.9ms\n",
      "30:\tlearn: 18.6839350\ttotal: 47.4ms\tremaining: 44.4ms\n",
      "31:\tlearn: 18.6740559\ttotal: 48.4ms\tremaining: 42.3ms\n",
      "32:\tlearn: 18.5574983\ttotal: 49.9ms\tremaining: 40.8ms\n",
      "33:\tlearn: 18.3926706\ttotal: 51.4ms\tremaining: 39.3ms\n",
      "34:\tlearn: 18.3179559\ttotal: 52.8ms\tremaining: 37.7ms\n",
      "35:\tlearn: 18.1814168\ttotal: 54.4ms\tremaining: 36.2ms\n",
      "36:\tlearn: 18.1163991\ttotal: 55.8ms\tremaining: 34.7ms\n",
      "37:\tlearn: 17.9317724\ttotal: 57.3ms\tremaining: 33.1ms\n",
      "38:\tlearn: 17.7884348\ttotal: 58.8ms\tremaining: 31.6ms\n",
      "39:\tlearn: 17.6653121\ttotal: 60.3ms\tremaining: 30.2ms\n",
      "40:\tlearn: 17.5060514\ttotal: 61.9ms\tremaining: 28.7ms\n",
      "41:\tlearn: 17.3573319\ttotal: 63.4ms\tremaining: 27.2ms\n",
      "42:\tlearn: 17.2303465\ttotal: 65ms\tremaining: 25.7ms\n",
      "43:\tlearn: 17.1243971\ttotal: 66.5ms\tremaining: 24.2ms\n",
      "44:\tlearn: 16.9803163\ttotal: 68ms\tremaining: 22.7ms\n",
      "45:\tlearn: 16.9219212\ttotal: 69.5ms\tremaining: 21.1ms\n",
      "46:\tlearn: 16.8501285\ttotal: 71ms\tremaining: 19.6ms\n",
      "47:\tlearn: 16.7706105\ttotal: 72.6ms\tremaining: 18.1ms\n",
      "48:\tlearn: 16.7486925\ttotal: 74ms\tremaining: 16.6ms\n",
      "49:\tlearn: 16.6619177\ttotal: 75.4ms\tremaining: 15.1ms\n",
      "50:\tlearn: 16.5161218\ttotal: 77ms\tremaining: 13.6ms\n",
      "51:\tlearn: 16.4586055\ttotal: 78.5ms\tremaining: 12.1ms\n",
      "52:\tlearn: 16.4079372\ttotal: 79.8ms\tremaining: 10.5ms\n",
      "53:\tlearn: 16.3108324\ttotal: 81.3ms\tremaining: 9.03ms\n",
      "54:\tlearn: 16.2134074\ttotal: 82.8ms\tremaining: 7.52ms\n",
      "55:\tlearn: 16.1376891\ttotal: 84.3ms\tremaining: 6.02ms\n",
      "56:\tlearn: 16.0559269\ttotal: 85.8ms\tremaining: 4.52ms\n",
      "57:\tlearn: 16.0544781\ttotal: 87.2ms\tremaining: 3ms\n",
      "58:\tlearn: 15.9440414\ttotal: 88.7ms\tremaining: 1.5ms\n",
      "59:\tlearn: 15.8677806\ttotal: 90.2ms\tremaining: 0us\n",
      "Valuaci√≥n de dataset de prueba en cat_model:  0.2764928797690033\n",
      "\n",
      "RMSE CatBoost model prueba: 49.801842046542056\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Por √∫ltimo observamos como funciona el modelo CatBoost\n",
    "cat_model = CatBoostRegressor(iterations=60, max_depth=7, learning_rate=0.4, loss_function='RMSE', random_state=12345)\n",
    "cat_model.fit(feat_train, target_train)\n",
    "cat_predict = cat_model.predict(feat_test)\n",
    "print(\"Valuaci√≥n de dataset de prueba en cat_model: \", cat_model.score(feat_test, target_test))\n",
    "print()\n",
    "print(f\"RMSE CatBoost model prueba: {rmse(cat_predict, target_test)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 33.7946670\ttotal: 899us\tremaining: 53ms\n",
      "1:\tlearn: 31.2222648\ttotal: 1.68ms\tremaining: 48.8ms\n",
      "2:\tlearn: 28.3893865\ttotal: 2.32ms\tremaining: 44.1ms\n",
      "3:\tlearn: 26.6986654\ttotal: 2.94ms\tremaining: 41.2ms\n",
      "4:\tlearn: 25.9156536\ttotal: 3.56ms\tremaining: 39.2ms\n",
      "5:\tlearn: 25.5650418\ttotal: 4.23ms\tremaining: 38.1ms\n",
      "6:\tlearn: 25.3295365\ttotal: 4.83ms\tremaining: 36.6ms\n",
      "7:\tlearn: 24.8172035\ttotal: 5.46ms\tremaining: 35.5ms\n",
      "8:\tlearn: 24.5877400\ttotal: 6.08ms\tremaining: 34.4ms\n",
      "9:\tlearn: 24.4281783\ttotal: 6.73ms\tremaining: 33.7ms\n",
      "10:\tlearn: 24.2740864\ttotal: 7.32ms\tremaining: 32.6ms\n",
      "11:\tlearn: 24.1309342\ttotal: 7.94ms\tremaining: 31.8ms\n",
      "12:\tlearn: 23.9334170\ttotal: 8.55ms\tremaining: 30.9ms\n",
      "13:\tlearn: 23.8929038\ttotal: 9.11ms\tremaining: 29.9ms\n",
      "14:\tlearn: 23.3930603\ttotal: 9.71ms\tremaining: 29.1ms\n",
      "15:\tlearn: 23.1522970\ttotal: 10.3ms\tremaining: 28.3ms\n",
      "16:\tlearn: 22.9251853\ttotal: 10.9ms\tremaining: 27.6ms\n",
      "17:\tlearn: 22.7378663\ttotal: 11.5ms\tremaining: 26.8ms\n",
      "18:\tlearn: 22.6998160\ttotal: 12.1ms\tremaining: 26.1ms\n",
      "19:\tlearn: 22.6054728\ttotal: 12.7ms\tremaining: 25.4ms\n",
      "20:\tlearn: 22.3759231\ttotal: 13.3ms\tremaining: 24.6ms\n",
      "21:\tlearn: 22.1962727\ttotal: 13.9ms\tremaining: 24ms\n",
      "22:\tlearn: 22.1721191\ttotal: 14.4ms\tremaining: 23.2ms\n",
      "23:\tlearn: 22.1489008\ttotal: 15ms\tremaining: 22.5ms\n",
      "24:\tlearn: 21.8221424\ttotal: 15.6ms\tremaining: 21.8ms\n",
      "25:\tlearn: 21.6311507\ttotal: 16.2ms\tremaining: 21.2ms\n",
      "26:\tlearn: 21.4882732\ttotal: 16.8ms\tremaining: 20.5ms\n",
      "27:\tlearn: 21.3833216\ttotal: 17.4ms\tremaining: 19.9ms\n",
      "28:\tlearn: 21.3639116\ttotal: 17.9ms\tremaining: 19.2ms\n",
      "29:\tlearn: 21.3493985\ttotal: 18.5ms\tremaining: 18.5ms\n",
      "30:\tlearn: 21.2110207\ttotal: 19.1ms\tremaining: 17.9ms\n",
      "31:\tlearn: 21.1163865\ttotal: 19.7ms\tremaining: 17.3ms\n",
      "32:\tlearn: 20.9572502\ttotal: 20.3ms\tremaining: 16.6ms\n",
      "33:\tlearn: 20.9444822\ttotal: 20.9ms\tremaining: 16ms\n",
      "34:\tlearn: 20.7626551\ttotal: 21.5ms\tremaining: 15.3ms\n",
      "35:\tlearn: 20.7486187\ttotal: 22ms\tremaining: 14.7ms\n",
      "36:\tlearn: 20.6453784\ttotal: 22.6ms\tremaining: 14.1ms\n",
      "37:\tlearn: 20.5520307\ttotal: 23.3ms\tremaining: 13.5ms\n",
      "38:\tlearn: 20.5403378\ttotal: 23.9ms\tremaining: 12.9ms\n",
      "39:\tlearn: 20.4565830\ttotal: 24.7ms\tremaining: 12.3ms\n",
      "40:\tlearn: 20.3456232\ttotal: 25.5ms\tremaining: 11.8ms\n",
      "41:\tlearn: 20.2859378\ttotal: 26.3ms\tremaining: 11.3ms\n",
      "42:\tlearn: 20.2784765\ttotal: 27ms\tremaining: 10.7ms\n",
      "43:\tlearn: 20.2055307\ttotal: 27.9ms\tremaining: 10.1ms\n",
      "44:\tlearn: 20.1374487\ttotal: 28.7ms\tremaining: 9.56ms\n",
      "45:\tlearn: 20.0881594\ttotal: 29.5ms\tremaining: 8.96ms\n",
      "46:\tlearn: 19.9779560\ttotal: 30.2ms\tremaining: 8.37ms\n",
      "47:\tlearn: 19.9073211\ttotal: 31ms\tremaining: 7.75ms\n",
      "48:\tlearn: 19.8555576\ttotal: 31.7ms\tremaining: 7.11ms\n",
      "49:\tlearn: 19.7761396\ttotal: 32.3ms\tremaining: 6.45ms\n",
      "50:\tlearn: 19.6998706\ttotal: 32.9ms\tremaining: 5.8ms\n",
      "51:\tlearn: 19.6926434\ttotal: 33.4ms\tremaining: 5.14ms\n",
      "52:\tlearn: 19.6382248\ttotal: 34ms\tremaining: 4.49ms\n",
      "53:\tlearn: 19.5815034\ttotal: 34.6ms\tremaining: 3.84ms\n",
      "54:\tlearn: 19.5230516\ttotal: 35.2ms\tremaining: 3.2ms\n",
      "55:\tlearn: 19.4691930\ttotal: 35.8ms\tremaining: 2.55ms\n",
      "56:\tlearn: 19.4169261\ttotal: 36.3ms\tremaining: 1.91ms\n",
      "57:\tlearn: 19.3072181\ttotal: 36.9ms\tremaining: 1.27ms\n",
      "58:\tlearn: 19.2469524\ttotal: 37.6ms\tremaining: 636us\n",
      "59:\tlearn: 19.1860314\ttotal: 38.1ms\tremaining: 0us\n",
      "Profundidad m√°xima: 4\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en cat_model:  0.4215658193267299\n",
      "\n",
      "RMSE CatBoost model prueba: 44.529823722128974\n",
      "\n",
      "0:\tlearn: 32.3828967\ttotal: 1.33ms\tremaining: 78.6ms\n",
      "1:\tlearn: 29.3426586\ttotal: 2.13ms\tremaining: 61.9ms\n",
      "2:\tlearn: 27.0225838\ttotal: 2.96ms\tremaining: 56.3ms\n",
      "3:\tlearn: 25.6538045\ttotal: 3.77ms\tremaining: 52.8ms\n",
      "4:\tlearn: 24.8306056\ttotal: 4.58ms\tremaining: 50.4ms\n",
      "5:\tlearn: 24.3172323\ttotal: 5.38ms\tremaining: 48.4ms\n",
      "6:\tlearn: 24.1460477\ttotal: 6.14ms\tremaining: 46.5ms\n",
      "7:\tlearn: 23.6796977\ttotal: 6.91ms\tremaining: 44.9ms\n",
      "8:\tlearn: 23.4246025\ttotal: 7.69ms\tremaining: 43.6ms\n",
      "9:\tlearn: 23.3591153\ttotal: 8.42ms\tremaining: 42.1ms\n",
      "10:\tlearn: 23.0370476\ttotal: 9.22ms\tremaining: 41.1ms\n",
      "11:\tlearn: 22.8700369\ttotal: 9.95ms\tremaining: 39.8ms\n",
      "12:\tlearn: 22.5315993\ttotal: 10.7ms\tremaining: 38.7ms\n",
      "13:\tlearn: 22.3562847\ttotal: 11.5ms\tremaining: 37.8ms\n",
      "14:\tlearn: 22.1996882\ttotal: 12.3ms\tremaining: 36.8ms\n",
      "15:\tlearn: 21.9091928\ttotal: 13.1ms\tremaining: 35.9ms\n",
      "16:\tlearn: 21.7508960\ttotal: 13.8ms\tremaining: 35ms\n",
      "17:\tlearn: 21.5506848\ttotal: 14.6ms\tremaining: 34.1ms\n",
      "18:\tlearn: 21.4756416\ttotal: 15.4ms\tremaining: 33.3ms\n",
      "19:\tlearn: 21.3594147\ttotal: 16.2ms\tremaining: 32.4ms\n",
      "20:\tlearn: 21.1505913\ttotal: 17ms\tremaining: 31.6ms\n",
      "21:\tlearn: 21.0549517\ttotal: 17.8ms\tremaining: 30.7ms\n",
      "22:\tlearn: 21.0029453\ttotal: 18.5ms\tremaining: 29.7ms\n",
      "23:\tlearn: 20.8938280\ttotal: 19.2ms\tremaining: 28.9ms\n",
      "24:\tlearn: 20.7325552\ttotal: 20ms\tremaining: 28ms\n",
      "25:\tlearn: 20.6086620\ttotal: 20.8ms\tremaining: 27.2ms\n",
      "26:\tlearn: 20.4575734\ttotal: 21.6ms\tremaining: 26.4ms\n",
      "27:\tlearn: 20.4408374\ttotal: 22.3ms\tremaining: 25.5ms\n",
      "28:\tlearn: 20.4287891\ttotal: 23ms\tremaining: 24.6ms\n",
      "29:\tlearn: 20.3394734\ttotal: 23.8ms\tremaining: 23.8ms\n",
      "30:\tlearn: 20.1870211\ttotal: 24.6ms\tremaining: 23ms\n",
      "31:\tlearn: 20.1725120\ttotal: 25.3ms\tremaining: 22.1ms\n",
      "32:\tlearn: 20.0868534\ttotal: 26.1ms\tremaining: 21.3ms\n",
      "33:\tlearn: 19.9647789\ttotal: 26.9ms\tremaining: 20.5ms\n",
      "34:\tlearn: 19.9526899\ttotal: 27.5ms\tremaining: 19.7ms\n",
      "35:\tlearn: 19.8253137\ttotal: 28.3ms\tremaining: 18.9ms\n",
      "36:\tlearn: 19.7158926\ttotal: 29.1ms\tremaining: 18.1ms\n",
      "37:\tlearn: 19.5645281\ttotal: 29.8ms\tremaining: 17.3ms\n",
      "38:\tlearn: 19.4991192\ttotal: 30.6ms\tremaining: 16.5ms\n",
      "39:\tlearn: 19.3891762\ttotal: 31.4ms\tremaining: 15.7ms\n",
      "40:\tlearn: 19.3251815\ttotal: 32.1ms\tremaining: 14.9ms\n",
      "41:\tlearn: 19.1691695\ttotal: 32.9ms\tremaining: 14.1ms\n",
      "42:\tlearn: 19.0893754\ttotal: 33.7ms\tremaining: 13.3ms\n",
      "43:\tlearn: 19.0373548\ttotal: 34.5ms\tremaining: 12.5ms\n",
      "44:\tlearn: 18.9995407\ttotal: 35.2ms\tremaining: 11.7ms\n",
      "45:\tlearn: 18.8896677\ttotal: 36ms\tremaining: 10.9ms\n",
      "46:\tlearn: 18.8312806\ttotal: 36.7ms\tremaining: 10.2ms\n",
      "47:\tlearn: 18.8218169\ttotal: 37.4ms\tremaining: 9.35ms\n",
      "48:\tlearn: 18.7359145\ttotal: 38.2ms\tremaining: 8.57ms\n",
      "49:\tlearn: 18.7293817\ttotal: 38.9ms\tremaining: 7.77ms\n",
      "50:\tlearn: 18.6357489\ttotal: 39.6ms\tremaining: 7ms\n",
      "51:\tlearn: 18.5661970\ttotal: 40.4ms\tremaining: 6.22ms\n",
      "52:\tlearn: 18.4972874\ttotal: 41.3ms\tremaining: 5.45ms\n",
      "53:\tlearn: 18.4551695\ttotal: 42ms\tremaining: 4.67ms\n",
      "54:\tlearn: 18.3984532\ttotal: 42.8ms\tremaining: 3.89ms\n",
      "55:\tlearn: 18.3435272\ttotal: 43.6ms\tremaining: 3.11ms\n",
      "56:\tlearn: 18.2474970\ttotal: 44.4ms\tremaining: 2.34ms\n",
      "57:\tlearn: 18.1431144\ttotal: 45.2ms\tremaining: 1.56ms\n",
      "58:\tlearn: 18.0935848\ttotal: 45.9ms\tremaining: 778us\n",
      "59:\tlearn: 18.0548242\ttotal: 46.7ms\tremaining: 0us\n",
      "Profundidad m√°xima: 5\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en cat_model:  0.3510245793131386\n",
      "\n",
      "RMSE CatBoost model prueba: 47.16698607183311\n",
      "\n",
      "0:\tlearn: 32.2631648\ttotal: 1.17ms\tremaining: 69.2ms\n",
      "1:\tlearn: 28.9314537\ttotal: 2.29ms\tremaining: 66.4ms\n",
      "2:\tlearn: 26.7748028\ttotal: 3.36ms\tremaining: 63.9ms\n",
      "3:\tlearn: 25.8385246\ttotal: 4.45ms\tremaining: 62.3ms\n",
      "4:\tlearn: 24.9488852\ttotal: 5.48ms\tremaining: 60.3ms\n",
      "5:\tlearn: 24.2855289\ttotal: 6.51ms\tremaining: 58.6ms\n",
      "6:\tlearn: 23.6415231\ttotal: 7.58ms\tremaining: 57.4ms\n",
      "7:\tlearn: 23.5887171\ttotal: 8.16ms\tremaining: 53.1ms\n",
      "8:\tlearn: 23.4794424\ttotal: 9.14ms\tremaining: 51.8ms\n",
      "9:\tlearn: 22.9719712\ttotal: 10.1ms\tremaining: 50.7ms\n",
      "10:\tlearn: 22.7192639\ttotal: 11.2ms\tremaining: 49.7ms\n",
      "11:\tlearn: 22.4256125\ttotal: 12.2ms\tremaining: 48.9ms\n",
      "12:\tlearn: 22.1734238\ttotal: 13.3ms\tremaining: 48ms\n",
      "13:\tlearn: 22.0805658\ttotal: 14.3ms\tremaining: 47.1ms\n",
      "14:\tlearn: 21.6936732\ttotal: 15.4ms\tremaining: 46.1ms\n",
      "15:\tlearn: 21.5133019\ttotal: 16.4ms\tremaining: 45.1ms\n",
      "16:\tlearn: 21.3422370\ttotal: 17.4ms\tremaining: 44.1ms\n",
      "17:\tlearn: 21.0702886\ttotal: 18.5ms\tremaining: 43.2ms\n",
      "18:\tlearn: 20.9092366\ttotal: 19.6ms\tremaining: 42.3ms\n",
      "19:\tlearn: 20.8562543\ttotal: 20.6ms\tremaining: 41.2ms\n",
      "20:\tlearn: 20.8369822\ttotal: 21.6ms\tremaining: 40.1ms\n",
      "21:\tlearn: 20.7086945\ttotal: 22.7ms\tremaining: 39.1ms\n",
      "22:\tlearn: 20.5363944\ttotal: 23.7ms\tremaining: 38.1ms\n",
      "23:\tlearn: 20.3518773\ttotal: 24.8ms\tremaining: 37.2ms\n",
      "24:\tlearn: 20.0147256\ttotal: 25.8ms\tremaining: 36.1ms\n",
      "25:\tlearn: 19.8166442\ttotal: 26.9ms\tremaining: 35.2ms\n",
      "26:\tlearn: 19.8034262\ttotal: 27.9ms\tremaining: 34.1ms\n",
      "27:\tlearn: 19.6008037\ttotal: 29ms\tremaining: 33.1ms\n",
      "28:\tlearn: 19.4485758\ttotal: 30ms\tremaining: 32.1ms\n",
      "29:\tlearn: 19.3697761\ttotal: 31ms\tremaining: 31ms\n",
      "30:\tlearn: 19.1978559\ttotal: 32ms\tremaining: 30ms\n",
      "31:\tlearn: 19.0701454\ttotal: 33.1ms\tremaining: 28.9ms\n",
      "32:\tlearn: 19.0004196\ttotal: 34.1ms\tremaining: 27.9ms\n",
      "33:\tlearn: 18.8245652\ttotal: 35.1ms\tremaining: 26.9ms\n",
      "34:\tlearn: 18.7438259\ttotal: 36.2ms\tremaining: 25.8ms\n",
      "35:\tlearn: 18.6516467\ttotal: 37.2ms\tremaining: 24.8ms\n",
      "36:\tlearn: 18.6409639\ttotal: 38.1ms\tremaining: 23.7ms\n",
      "37:\tlearn: 18.5635895\ttotal: 39.2ms\tremaining: 22.7ms\n",
      "38:\tlearn: 18.4507936\ttotal: 40.2ms\tremaining: 21.6ms\n",
      "39:\tlearn: 18.3174447\ttotal: 41.2ms\tremaining: 20.6ms\n",
      "40:\tlearn: 18.2220727\ttotal: 42.3ms\tremaining: 19.6ms\n",
      "41:\tlearn: 18.0945670\ttotal: 43.4ms\tremaining: 18.6ms\n",
      "42:\tlearn: 18.0365710\ttotal: 44.4ms\tremaining: 17.5ms\n",
      "43:\tlearn: 17.9511203\ttotal: 45.4ms\tremaining: 16.5ms\n",
      "44:\tlearn: 17.8930627\ttotal: 46.5ms\tremaining: 15.5ms\n",
      "45:\tlearn: 17.8122990\ttotal: 47.5ms\tremaining: 14.5ms\n",
      "46:\tlearn: 17.7733286\ttotal: 48.5ms\tremaining: 13.4ms\n",
      "47:\tlearn: 17.6638376\ttotal: 49.5ms\tremaining: 12.4ms\n",
      "48:\tlearn: 17.6061696\ttotal: 50.6ms\tremaining: 11.4ms\n",
      "49:\tlearn: 17.5025672\ttotal: 51.6ms\tremaining: 10.3ms\n",
      "50:\tlearn: 17.3766238\ttotal: 52.7ms\tremaining: 9.29ms\n",
      "51:\tlearn: 17.3438279\ttotal: 53.6ms\tremaining: 8.25ms\n",
      "52:\tlearn: 17.2721400\ttotal: 54.7ms\tremaining: 7.22ms\n",
      "53:\tlearn: 17.1779314\ttotal: 55.7ms\tremaining: 6.19ms\n",
      "54:\tlearn: 17.0710144\ttotal: 56.8ms\tremaining: 5.16ms\n",
      "55:\tlearn: 16.9909203\ttotal: 57.8ms\tremaining: 4.13ms\n",
      "56:\tlearn: 16.9525644\ttotal: 58.8ms\tremaining: 3.1ms\n",
      "57:\tlearn: 16.8783683\ttotal: 59.9ms\tremaining: 2.07ms\n",
      "58:\tlearn: 16.7855593\ttotal: 61ms\tremaining: 1.03ms\n",
      "59:\tlearn: 16.7068025\ttotal: 62.1ms\tremaining: 0us\n",
      "Profundidad m√°xima: 6\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en cat_model:  0.37761154830021004\n",
      "\n",
      "RMSE CatBoost model prueba: 46.19072348917672\n",
      "\n",
      "0:\tlearn: 32.1081976\ttotal: 1.97ms\tremaining: 116ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\tlearn: 28.2555847\ttotal: 3.68ms\tremaining: 107ms\n",
      "2:\tlearn: 26.2832391\ttotal: 5.34ms\tremaining: 101ms\n",
      "3:\tlearn: 25.0724734\ttotal: 6.91ms\tremaining: 96.8ms\n",
      "4:\tlearn: 24.1793293\ttotal: 8.46ms\tremaining: 93.1ms\n",
      "5:\tlearn: 23.5944209\ttotal: 9.96ms\tremaining: 89.6ms\n",
      "6:\tlearn: 23.2351080\ttotal: 11.4ms\tremaining: 86.5ms\n",
      "7:\tlearn: 22.9306457\ttotal: 12.9ms\tremaining: 83.6ms\n",
      "8:\tlearn: 22.6633001\ttotal: 14.4ms\tremaining: 81.8ms\n",
      "9:\tlearn: 22.4973205\ttotal: 15.9ms\tremaining: 79.4ms\n",
      "10:\tlearn: 22.0068204\ttotal: 17.4ms\tremaining: 77.4ms\n",
      "11:\tlearn: 21.9672251\ttotal: 18.9ms\tremaining: 75.4ms\n",
      "12:\tlearn: 21.7536910\ttotal: 20.4ms\tremaining: 73.7ms\n",
      "13:\tlearn: 21.4333996\ttotal: 22ms\tremaining: 72.3ms\n",
      "14:\tlearn: 21.2340231\ttotal: 23.5ms\tremaining: 70.5ms\n",
      "15:\tlearn: 20.9778467\ttotal: 25ms\tremaining: 68.7ms\n",
      "16:\tlearn: 20.7822810\ttotal: 26.5ms\tremaining: 67.1ms\n",
      "17:\tlearn: 20.6414963\ttotal: 28ms\tremaining: 65.3ms\n",
      "18:\tlearn: 20.5212220\ttotal: 29.5ms\tremaining: 63.7ms\n",
      "19:\tlearn: 20.2590320\ttotal: 31ms\tremaining: 62ms\n",
      "20:\tlearn: 20.0525890\ttotal: 32.5ms\tremaining: 60.4ms\n",
      "21:\tlearn: 19.8215413\ttotal: 34.1ms\tremaining: 58.8ms\n",
      "22:\tlearn: 19.6677800\ttotal: 35.6ms\tremaining: 57.3ms\n",
      "23:\tlearn: 19.5844846\ttotal: 37.1ms\tremaining: 55.6ms\n",
      "24:\tlearn: 19.3242596\ttotal: 38.7ms\tremaining: 54.1ms\n",
      "25:\tlearn: 19.3066212\ttotal: 40ms\tremaining: 52.3ms\n",
      "26:\tlearn: 19.1297655\ttotal: 41.6ms\tremaining: 50.8ms\n",
      "27:\tlearn: 19.1035083\ttotal: 42.9ms\tremaining: 49.1ms\n",
      "28:\tlearn: 18.9806280\ttotal: 44.5ms\tremaining: 47.5ms\n",
      "29:\tlearn: 18.8310632\ttotal: 46ms\tremaining: 46ms\n",
      "30:\tlearn: 18.6839350\ttotal: 47.5ms\tremaining: 44.4ms\n",
      "31:\tlearn: 18.6740559\ttotal: 48.4ms\tremaining: 42.3ms\n",
      "32:\tlearn: 18.5574983\ttotal: 49.8ms\tremaining: 40.8ms\n",
      "33:\tlearn: 18.3926706\ttotal: 51.4ms\tremaining: 39.3ms\n",
      "34:\tlearn: 18.3179559\ttotal: 52.8ms\tremaining: 37.7ms\n",
      "35:\tlearn: 18.1814168\ttotal: 54.3ms\tremaining: 36.2ms\n",
      "36:\tlearn: 18.1163991\ttotal: 55.8ms\tremaining: 34.7ms\n",
      "37:\tlearn: 17.9317724\ttotal: 57.3ms\tremaining: 33.1ms\n",
      "38:\tlearn: 17.7884348\ttotal: 58.7ms\tremaining: 31.6ms\n",
      "39:\tlearn: 17.6653121\ttotal: 60.3ms\tremaining: 30.1ms\n",
      "40:\tlearn: 17.5060514\ttotal: 61.9ms\tremaining: 28.7ms\n",
      "41:\tlearn: 17.3573319\ttotal: 63.4ms\tremaining: 27.2ms\n",
      "42:\tlearn: 17.2303465\ttotal: 65ms\tremaining: 25.7ms\n",
      "43:\tlearn: 17.1243971\ttotal: 66.5ms\tremaining: 24.2ms\n",
      "44:\tlearn: 16.9803163\ttotal: 68.1ms\tremaining: 22.7ms\n",
      "45:\tlearn: 16.9219212\ttotal: 69.5ms\tremaining: 21.1ms\n",
      "46:\tlearn: 16.8501285\ttotal: 71ms\tremaining: 19.6ms\n",
      "47:\tlearn: 16.7706105\ttotal: 72.6ms\tremaining: 18.1ms\n",
      "48:\tlearn: 16.7486925\ttotal: 73.9ms\tremaining: 16.6ms\n",
      "49:\tlearn: 16.6619177\ttotal: 75.4ms\tremaining: 15.1ms\n",
      "50:\tlearn: 16.5161218\ttotal: 76.9ms\tremaining: 13.6ms\n",
      "51:\tlearn: 16.4586055\ttotal: 78.4ms\tremaining: 12.1ms\n",
      "52:\tlearn: 16.4079372\ttotal: 79.8ms\tremaining: 10.5ms\n",
      "53:\tlearn: 16.3108324\ttotal: 81.3ms\tremaining: 9.03ms\n",
      "54:\tlearn: 16.2134074\ttotal: 82.8ms\tremaining: 7.53ms\n",
      "55:\tlearn: 16.1376891\ttotal: 84.4ms\tremaining: 6.03ms\n",
      "56:\tlearn: 16.0559269\ttotal: 85.8ms\tremaining: 4.52ms\n",
      "57:\tlearn: 16.0544781\ttotal: 87.2ms\tremaining: 3.01ms\n",
      "58:\tlearn: 15.9440414\ttotal: 88.7ms\tremaining: 1.5ms\n",
      "59:\tlearn: 15.8677806\ttotal: 90.2ms\tremaining: 0us\n",
      "Profundidad m√°xima: 7\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en cat_model:  0.2764928797690033\n",
      "\n",
      "RMSE CatBoost model prueba: 49.801842046542056\n",
      "\n",
      "0:\tlearn: 32.0529064\ttotal: 3.49ms\tremaining: 206ms\n",
      "1:\tlearn: 28.3005145\ttotal: 6.04ms\tremaining: 175ms\n",
      "2:\tlearn: 25.8718802\ttotal: 8.41ms\tremaining: 160ms\n",
      "3:\tlearn: 24.7278021\ttotal: 10.9ms\tremaining: 152ms\n",
      "4:\tlearn: 24.1947854\ttotal: 13.2ms\tremaining: 145ms\n",
      "5:\tlearn: 23.3049768\ttotal: 15.7ms\tremaining: 141ms\n",
      "6:\tlearn: 22.7003844\ttotal: 18.1ms\tremaining: 137ms\n",
      "7:\tlearn: 22.4541500\ttotal: 20.6ms\tremaining: 134ms\n",
      "8:\tlearn: 22.2932153\ttotal: 22.9ms\tremaining: 130ms\n",
      "9:\tlearn: 21.9889854\ttotal: 25.3ms\tremaining: 127ms\n",
      "10:\tlearn: 21.6836785\ttotal: 27.6ms\tremaining: 123ms\n",
      "11:\tlearn: 21.1061045\ttotal: 30ms\tremaining: 120ms\n",
      "12:\tlearn: 20.8736365\ttotal: 33ms\tremaining: 119ms\n",
      "13:\tlearn: 20.6086442\ttotal: 35.4ms\tremaining: 116ms\n",
      "14:\tlearn: 20.4986436\ttotal: 37.6ms\tremaining: 113ms\n",
      "15:\tlearn: 20.4750031\ttotal: 38.2ms\tremaining: 105ms\n",
      "16:\tlearn: 20.3297046\ttotal: 40.6ms\tremaining: 103ms\n",
      "17:\tlearn: 20.2484564\ttotal: 42.9ms\tremaining: 100ms\n",
      "18:\tlearn: 20.0366329\ttotal: 45.3ms\tremaining: 97.8ms\n",
      "19:\tlearn: 19.9121535\ttotal: 47.8ms\tremaining: 95.6ms\n",
      "20:\tlearn: 19.6353540\ttotal: 50.5ms\tremaining: 93.8ms\n",
      "21:\tlearn: 19.5494534\ttotal: 53ms\tremaining: 91.5ms\n",
      "22:\tlearn: 19.1805850\ttotal: 55.6ms\tremaining: 89.5ms\n",
      "23:\tlearn: 18.9551626\ttotal: 58ms\tremaining: 87ms\n",
      "24:\tlearn: 18.7874105\ttotal: 60.3ms\tremaining: 84.5ms\n",
      "25:\tlearn: 18.6938085\ttotal: 62.6ms\tremaining: 81.9ms\n",
      "26:\tlearn: 18.5223744\ttotal: 65ms\tremaining: 79.5ms\n",
      "27:\tlearn: 18.3225932\ttotal: 67.3ms\tremaining: 76.9ms\n",
      "28:\tlearn: 18.0547581\ttotal: 69.8ms\tremaining: 74.6ms\n",
      "29:\tlearn: 18.0444341\ttotal: 71.2ms\tremaining: 71.2ms\n",
      "30:\tlearn: 18.0318383\ttotal: 73.5ms\tremaining: 68.8ms\n",
      "31:\tlearn: 17.8385102\ttotal: 75.9ms\tremaining: 66.4ms\n",
      "32:\tlearn: 17.6572142\ttotal: 78.3ms\tremaining: 64.1ms\n",
      "33:\tlearn: 17.4618721\ttotal: 80.9ms\tremaining: 61.9ms\n",
      "34:\tlearn: 17.3612861\ttotal: 83.2ms\tremaining: 59.4ms\n",
      "35:\tlearn: 17.1727274\ttotal: 85.6ms\tremaining: 57.1ms\n",
      "36:\tlearn: 17.0041100\ttotal: 88.1ms\tremaining: 54.7ms\n",
      "37:\tlearn: 16.9039605\ttotal: 90.5ms\tremaining: 52.4ms\n",
      "38:\tlearn: 16.7673367\ttotal: 92.8ms\tremaining: 50ms\n",
      "39:\tlearn: 16.5696507\ttotal: 95.2ms\tremaining: 47.6ms\n",
      "40:\tlearn: 16.5078386\ttotal: 97.6ms\tremaining: 45.2ms\n",
      "41:\tlearn: 16.3742745\ttotal: 99.9ms\tremaining: 42.8ms\n",
      "42:\tlearn: 16.1893800\ttotal: 102ms\tremaining: 40.4ms\n",
      "43:\tlearn: 16.0522880\ttotal: 105ms\tremaining: 38ms\n",
      "44:\tlearn: 15.9507588\ttotal: 107ms\tremaining: 35.7ms\n",
      "45:\tlearn: 15.8088527\ttotal: 110ms\tremaining: 33.3ms\n",
      "46:\tlearn: 15.7040135\ttotal: 112ms\tremaining: 31ms\n",
      "47:\tlearn: 15.4729134\ttotal: 115ms\tremaining: 28.6ms\n",
      "48:\tlearn: 15.3974691\ttotal: 117ms\tremaining: 26.3ms\n",
      "49:\tlearn: 15.2198056\ttotal: 119ms\tremaining: 23.9ms\n",
      "50:\tlearn: 15.0825301\ttotal: 122ms\tremaining: 21.5ms\n",
      "51:\tlearn: 14.9813342\ttotal: 124ms\tremaining: 19.1ms\n",
      "52:\tlearn: 14.8962947\ttotal: 127ms\tremaining: 16.7ms\n",
      "53:\tlearn: 14.7581697\ttotal: 129ms\tremaining: 14.3ms\n",
      "54:\tlearn: 14.7191271\ttotal: 131ms\tremaining: 11.9ms\n",
      "55:\tlearn: 14.6210640\ttotal: 134ms\tremaining: 9.55ms\n",
      "56:\tlearn: 14.5617332\ttotal: 136ms\tremaining: 7.16ms\n",
      "57:\tlearn: 14.4518947\ttotal: 138ms\tremaining: 4.77ms\n",
      "58:\tlearn: 14.4076580\ttotal: 141ms\tremaining: 2.39ms\n",
      "59:\tlearn: 14.2942571\ttotal: 143ms\tremaining: 0us\n",
      "Profundidad m√°xima: 8\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en cat_model:  0.31008445181135436\n",
      "\n",
      "RMSE CatBoost model prueba: 48.631981820175675\n",
      "\n",
      "0:\tlearn: 31.7155046\ttotal: 5.03ms\tremaining: 297ms\n",
      "1:\tlearn: 28.1835001\ttotal: 9.91ms\tremaining: 287ms\n",
      "2:\tlearn: 25.6894003\ttotal: 14ms\tremaining: 267ms\n",
      "3:\tlearn: 24.5400768\ttotal: 18.2ms\tremaining: 255ms\n",
      "4:\tlearn: 23.2119230\ttotal: 22.8ms\tremaining: 251ms\n",
      "5:\tlearn: 22.8661048\ttotal: 27ms\tremaining: 243ms\n",
      "6:\tlearn: 22.0171554\ttotal: 31ms\tremaining: 235ms\n",
      "7:\tlearn: 21.7264842\ttotal: 34.9ms\tremaining: 227ms\n",
      "8:\tlearn: 21.5278666\ttotal: 39.1ms\tremaining: 222ms\n",
      "9:\tlearn: 21.1473230\ttotal: 43.3ms\tremaining: 216ms\n",
      "10:\tlearn: 20.9028948\ttotal: 47.4ms\tremaining: 211ms\n",
      "11:\tlearn: 20.4511652\ttotal: 51.4ms\tremaining: 205ms\n",
      "12:\tlearn: 20.1372652\ttotal: 55.6ms\tremaining: 201ms\n",
      "13:\tlearn: 19.9818576\ttotal: 59.5ms\tremaining: 195ms\n",
      "14:\tlearn: 19.6808895\ttotal: 63.8ms\tremaining: 191ms\n",
      "15:\tlearn: 19.4833781\ttotal: 68ms\tremaining: 187ms\n",
      "16:\tlearn: 19.2791404\ttotal: 71.9ms\tremaining: 182ms\n",
      "17:\tlearn: 19.1739114\ttotal: 76ms\tremaining: 177ms\n",
      "18:\tlearn: 18.8563039\ttotal: 80.4ms\tremaining: 173ms\n",
      "19:\tlearn: 18.6506301\ttotal: 84.4ms\tremaining: 169ms\n",
      "20:\tlearn: 18.3053159\ttotal: 88.4ms\tremaining: 164ms\n",
      "21:\tlearn: 18.0540413\ttotal: 92.6ms\tremaining: 160ms\n",
      "22:\tlearn: 17.9037417\ttotal: 96.5ms\tremaining: 155ms\n",
      "23:\tlearn: 17.6259107\ttotal: 101ms\tremaining: 151ms\n",
      "24:\tlearn: 17.3699061\ttotal: 104ms\tremaining: 146ms\n",
      "25:\tlearn: 17.3148416\ttotal: 108ms\tremaining: 142ms\n",
      "26:\tlearn: 17.1126046\ttotal: 113ms\tremaining: 138ms\n",
      "27:\tlearn: 16.8815328\ttotal: 116ms\tremaining: 133ms\n",
      "28:\tlearn: 16.8524704\ttotal: 121ms\tremaining: 129ms\n",
      "29:\tlearn: 16.8323022\ttotal: 126ms\tremaining: 126ms\n",
      "30:\tlearn: 16.5486019\ttotal: 132ms\tremaining: 123ms\n",
      "31:\tlearn: 16.2508303\ttotal: 137ms\tremaining: 120ms\n",
      "32:\tlearn: 16.1880438\ttotal: 142ms\tremaining: 117ms\n",
      "33:\tlearn: 15.9981112\ttotal: 148ms\tremaining: 113ms\n",
      "34:\tlearn: 15.9845057\ttotal: 153ms\tremaining: 110ms\n",
      "35:\tlearn: 15.9819506\ttotal: 154ms\tremaining: 103ms\n",
      "36:\tlearn: 15.8444536\ttotal: 159ms\tremaining: 98.8ms\n",
      "37:\tlearn: 15.6318100\ttotal: 163ms\tremaining: 94.5ms\n",
      "38:\tlearn: 15.5271585\ttotal: 167ms\tremaining: 90.1ms\n",
      "39:\tlearn: 15.3787316\ttotal: 171ms\tremaining: 85.7ms\n",
      "40:\tlearn: 15.2985157\ttotal: 175ms\tremaining: 81.3ms\n",
      "41:\tlearn: 15.1309793\ttotal: 179ms\tremaining: 76.9ms\n",
      "42:\tlearn: 14.9419388\ttotal: 184ms\tremaining: 72.6ms\n",
      "43:\tlearn: 14.8089147\ttotal: 188ms\tremaining: 68.4ms\n",
      "44:\tlearn: 14.7440564\ttotal: 192ms\tremaining: 64ms\n",
      "45:\tlearn: 14.6562689\ttotal: 196ms\tremaining: 59.6ms\n",
      "46:\tlearn: 14.6106302\ttotal: 200ms\tremaining: 55.3ms\n",
      "47:\tlearn: 14.4622889\ttotal: 204ms\tremaining: 51ms\n",
      "48:\tlearn: 14.2838447\ttotal: 208ms\tremaining: 46.7ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49:\tlearn: 14.0908013\ttotal: 213ms\tremaining: 42.6ms\n",
      "50:\tlearn: 13.9690949\ttotal: 217ms\tremaining: 38.3ms\n",
      "51:\tlearn: 13.9171955\ttotal: 221ms\tremaining: 34.1ms\n",
      "52:\tlearn: 13.7426459\ttotal: 226ms\tremaining: 29.8ms\n",
      "53:\tlearn: 13.6345056\ttotal: 230ms\tremaining: 25.5ms\n",
      "54:\tlearn: 13.5559467\ttotal: 234ms\tremaining: 21.2ms\n",
      "55:\tlearn: 13.4174621\ttotal: 238ms\tremaining: 17ms\n",
      "56:\tlearn: 13.2611225\ttotal: 242ms\tremaining: 12.7ms\n",
      "57:\tlearn: 13.1841963\ttotal: 246ms\tremaining: 8.47ms\n",
      "58:\tlearn: 13.0642264\ttotal: 250ms\tremaining: 4.23ms\n",
      "59:\tlearn: 12.9960456\ttotal: 254ms\tremaining: 0us\n",
      "Profundidad m√°xima: 9\n",
      "\n",
      "Valuaci√≥n de dataset de prueba en cat_model:  0.27112373406862345\n",
      "\n",
      "RMSE CatBoost model prueba: 49.98629019459919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for depth in range (4, 10):\n",
    "    cat_model = CatBoostRegressor(iterations=60, max_depth=depth, learning_rate=0.4, loss_function='RMSE', random_state=12345)\n",
    "    cat_model.fit(feat_train, target_train)\n",
    "    cat_predict = cat_model.predict(feat_test)\n",
    "    print(\"Profundidad m√°xima:\", depth)\n",
    "    print()\n",
    "    print(\"Valuaci√≥n de dataset de prueba en cat_model: \", cat_model.score(feat_test, target_test))\n",
    "    print()\n",
    "    print(f\"RMSE CatBoost model prueba: {rmse(cat_predict, target_test)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 33.7946670\ttotal: 1.32ms\tremaining: 77.7ms\n",
      "1:\tlearn: 31.2222648\ttotal: 2.15ms\tremaining: 62.2ms\n",
      "2:\tlearn: 28.3893865\ttotal: 2.79ms\tremaining: 53ms\n",
      "3:\tlearn: 26.6986654\ttotal: 3.41ms\tremaining: 47.8ms\n",
      "4:\tlearn: 25.9156536\ttotal: 4.02ms\tremaining: 44.3ms\n",
      "5:\tlearn: 25.5650418\ttotal: 4.65ms\tremaining: 41.9ms\n",
      "6:\tlearn: 25.3295365\ttotal: 5.26ms\tremaining: 39.8ms\n",
      "7:\tlearn: 24.8172035\ttotal: 5.92ms\tremaining: 38.5ms\n",
      "8:\tlearn: 24.5877400\ttotal: 6.54ms\tremaining: 37.1ms\n",
      "9:\tlearn: 24.4281783\ttotal: 7.14ms\tremaining: 35.7ms\n",
      "10:\tlearn: 24.2740864\ttotal: 7.71ms\tremaining: 34.3ms\n",
      "11:\tlearn: 24.1309342\ttotal: 8.29ms\tremaining: 33.2ms\n",
      "12:\tlearn: 23.9334170\ttotal: 8.91ms\tremaining: 32.2ms\n",
      "13:\tlearn: 23.8929038\ttotal: 9.48ms\tremaining: 31.1ms\n",
      "14:\tlearn: 23.3930603\ttotal: 10.1ms\tremaining: 30.4ms\n",
      "15:\tlearn: 23.1522970\ttotal: 10.7ms\tremaining: 29.5ms\n",
      "16:\tlearn: 22.9251853\ttotal: 11.3ms\tremaining: 28.7ms\n",
      "17:\tlearn: 22.7378663\ttotal: 11.9ms\tremaining: 27.8ms\n",
      "18:\tlearn: 22.6998160\ttotal: 12.5ms\tremaining: 26.9ms\n",
      "19:\tlearn: 22.6054728\ttotal: 13.1ms\tremaining: 26.2ms\n",
      "20:\tlearn: 22.3759231\ttotal: 13.7ms\tremaining: 25.5ms\n",
      "21:\tlearn: 22.1962727\ttotal: 14.4ms\tremaining: 24.8ms\n",
      "22:\tlearn: 22.1721191\ttotal: 14.9ms\tremaining: 24ms\n",
      "23:\tlearn: 22.1489008\ttotal: 15.5ms\tremaining: 23.2ms\n",
      "24:\tlearn: 21.8221424\ttotal: 16.1ms\tremaining: 22.5ms\n",
      "25:\tlearn: 21.6311507\ttotal: 16.7ms\tremaining: 21.8ms\n",
      "26:\tlearn: 21.4882732\ttotal: 17.3ms\tremaining: 21.1ms\n",
      "27:\tlearn: 21.3833216\ttotal: 17.9ms\tremaining: 20.4ms\n",
      "28:\tlearn: 21.3639116\ttotal: 18.5ms\tremaining: 19.7ms\n",
      "29:\tlearn: 21.3493985\ttotal: 19ms\tremaining: 19ms\n",
      "30:\tlearn: 21.2110207\ttotal: 19.6ms\tremaining: 18.4ms\n",
      "31:\tlearn: 21.1163865\ttotal: 20.2ms\tremaining: 17.7ms\n",
      "32:\tlearn: 20.9572502\ttotal: 20.8ms\tremaining: 17.1ms\n",
      "33:\tlearn: 20.9444822\ttotal: 21.4ms\tremaining: 16.4ms\n",
      "34:\tlearn: 20.7626551\ttotal: 22ms\tremaining: 15.7ms\n",
      "35:\tlearn: 20.7486187\ttotal: 22.6ms\tremaining: 15.1ms\n",
      "36:\tlearn: 20.6453784\ttotal: 23.2ms\tremaining: 14.4ms\n",
      "37:\tlearn: 20.5520307\ttotal: 23.8ms\tremaining: 13.8ms\n",
      "38:\tlearn: 20.5403378\ttotal: 24.3ms\tremaining: 13.1ms\n",
      "39:\tlearn: 20.4565830\ttotal: 24.9ms\tremaining: 12.4ms\n",
      "40:\tlearn: 20.3456232\ttotal: 25.5ms\tremaining: 11.8ms\n",
      "41:\tlearn: 20.2859378\ttotal: 26.2ms\tremaining: 11.2ms\n",
      "42:\tlearn: 20.2784765\ttotal: 26.7ms\tremaining: 10.5ms\n",
      "43:\tlearn: 20.2055307\ttotal: 27.3ms\tremaining: 9.93ms\n",
      "44:\tlearn: 20.1374487\ttotal: 27.9ms\tremaining: 9.3ms\n",
      "45:\tlearn: 20.0881594\ttotal: 28.5ms\tremaining: 8.67ms\n",
      "46:\tlearn: 19.9779560\ttotal: 29.1ms\tremaining: 8.05ms\n",
      "47:\tlearn: 19.9073211\ttotal: 29.7ms\tremaining: 7.43ms\n",
      "48:\tlearn: 19.8555576\ttotal: 30.3ms\tremaining: 6.81ms\n",
      "49:\tlearn: 19.7761396\ttotal: 30.9ms\tremaining: 6.19ms\n",
      "50:\tlearn: 19.6998706\ttotal: 31.6ms\tremaining: 5.57ms\n",
      "51:\tlearn: 19.6926434\ttotal: 32.1ms\tremaining: 4.94ms\n",
      "52:\tlearn: 19.6382248\ttotal: 32.7ms\tremaining: 4.32ms\n",
      "53:\tlearn: 19.5815034\ttotal: 33.3ms\tremaining: 3.7ms\n",
      "54:\tlearn: 19.5230516\ttotal: 33.9ms\tremaining: 3.08ms\n",
      "55:\tlearn: 19.4691930\ttotal: 34.5ms\tremaining: 2.46ms\n",
      "56:\tlearn: 19.4169261\ttotal: 35ms\tremaining: 1.84ms\n",
      "57:\tlearn: 19.3072181\ttotal: 35.6ms\tremaining: 1.23ms\n",
      "58:\tlearn: 19.2469524\ttotal: 36.2ms\tremaining: 614us\n",
      "59:\tlearn: 19.1860314\ttotal: 36.8ms\tremaining: 0us\n",
      "Valuaci√≥n de dataset de prueba en cat_model:  0.4215658193267299\n",
      "\n",
      "RMSE CatBoost model prueba: 44.529823722128974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat_model = CatBoostRegressor(iterations=60, max_depth=4, learning_rate=0.4, loss_function='RMSE', random_state=12345)\n",
    "cat_model.fit(feat_train, target_train)\n",
    "cat_predict = cat_model.predict(feat_test)\n",
    "print(\"Valuaci√≥n de dataset de prueba en cat_model: \", cat_model.score(feat_test, target_test))\n",
    "print()\n",
    "print(f\"RMSE CatBoost model prueba: {rmse(cat_predict, target_test)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones modelo CatBoost\n",
    "\n",
    "Al iterar sobre este modelo llegamos a la conclusion que estos son los valores ideales para entrenar el modelo:\n",
    "\n",
    "Fijar el n√∫mero de iteraciones en 60, profunidad m√°xima por √°rbol en 4 y un learning rate de 0.4\n",
    "\n",
    "Con esta combinaci√≥n de valores llegamos a obtener un error m√≠nimo de 44.52 con el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Comentario del revisor (1ra Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "\n",
    "Buen avance con el proyecto Arturo! Si, veo que no se logr√≥ bajar a menos de 48 la m√©trica, te recomendar√≠a que extraigas un poco m√°s de informaci√≥n de los datos temporales para esto, por ejemplo, puedes agregar la hora del d√≠a al dataset para complementar mejor la informaci√≥n que le pasas a los modelos.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor (2da Iteracion)</b> <a class=‚ÄútocSkip‚Äù></a>\n",
    "\n",
    "Excelente trabajo Arturo, se nota que vas por buen camino como Data Scientist. Este proceso de experimentaci√≥n de poner o quitar caracter√≠sticas a los modelos es parte de una t√©cnica llamada `Feature Engineering`, y es normal que te tome un poco de tiempo llegar a la combinaci√≥n correcta para obtener el correcto desempe√±o de un modelo ya que eso es parte del proceso de experimentaci√≥n.\n",
    "    \n",
    "Saludos!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones Generales\n",
    "\n",
    "Al iterar nuestro modelos podemos observar que LightGBM y CatBoost llegan a satisfacer nuestro objetivos.\n",
    "En este caso yo recomendar√≠a utilizar el modelo CatBoost ya que alcanza el objetivo utilizando menos recursos, eficientando el tiempo computacional.\n",
    "Aunque LightGBM alcanza un error menor a CatBoost, el segundo modelo itera de manera m√°s r√°p√¨da y eficiente.\n",
    "Dejar√≠a la decisi√≥n a criterio del cliente, para que utilizen un modelo que m√°s les acomode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista de revisi√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  \t\n",
    "Jupyter Notebook est√° abierto.\n",
    "- [ ]  El c√≥digo no tiene errores\n",
    "- [ ]  Las celdas con el c√≥digo han sido colocadas en el orden de ejecuci√≥n.\n",
    "- [ ]  \t\n",
    "Los datos han sido descargados y preparados.\n",
    "- [ ]  Se ha realizado el paso 2: los datos han sido analizados\n",
    "- [ ]  Se entren√≥ el modelo y se seleccionaron los hiperpar√°metros\n",
    "- [ ]  Se han evaluado los modelos. Se expuso una conclusi√≥n\n",
    "- [ ] La *RECM* para el conjunto de prueba no es m√°s de 48"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 321,
    "start_time": "2024-12-19T21:47:53.472Z"
   },
   {
    "duration": 179,
    "start_time": "2024-12-19T21:48:52.350Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-19T21:49:21.211Z"
   },
   {
    "duration": 419,
    "start_time": "2024-12-19T21:49:56.171Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-19T21:50:14.188Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-19T21:50:22.518Z"
   },
   {
    "duration": 27,
    "start_time": "2024-12-19T21:50:47.644Z"
   },
   {
    "duration": 25,
    "start_time": "2024-12-19T22:24:04.626Z"
   },
   {
    "duration": 26,
    "start_time": "2024-12-19T22:24:36.990Z"
   },
   {
    "duration": 20,
    "start_time": "2024-12-19T22:27:33.318Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-19T22:27:39.535Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-19T22:27:50.361Z"
   },
   {
    "duration": 337,
    "start_time": "2024-12-19T22:29:04.502Z"
   },
   {
    "duration": 1837,
    "start_time": "2024-12-19T22:29:42.173Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-19T22:33:59.322Z"
   },
   {
    "duration": 597,
    "start_time": "2024-12-19T22:38:16.360Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-19T22:39:21.332Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-19T23:01:56.271Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-19T23:02:48.780Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-19T23:03:25.962Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-19T23:03:34.205Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-19T23:03:55.277Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-19T23:03:55.901Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-19T23:04:09.126Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-19T23:04:09.632Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-19T23:04:12.098Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-19T23:06:08.697Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-19T23:06:09.328Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-19T23:06:23.524Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-19T23:06:24.001Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-19T23:07:33.777Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-19T23:08:15.484Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-19T23:08:16.074Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-19T23:12:07.493Z"
   },
   {
    "duration": 812,
    "start_time": "2024-12-19T23:12:15.546Z"
   },
   {
    "duration": 31,
    "start_time": "2024-12-19T23:12:16.360Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-19T23:12:16.392Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-19T23:12:16.412Z"
   },
   {
    "duration": 517,
    "start_time": "2024-12-19T23:12:16.420Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-19T23:12:16.939Z"
   },
   {
    "duration": 71,
    "start_time": "2024-12-19T23:12:16.944Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-19T23:12:53.648Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-19T23:12:54.126Z"
   },
   {
    "duration": 758,
    "start_time": "2024-12-19T23:13:02.512Z"
   },
   {
    "duration": 27,
    "start_time": "2024-12-19T23:13:03.273Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-19T23:13:03.301Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-19T23:13:03.316Z"
   },
   {
    "duration": 552,
    "start_time": "2024-12-19T23:13:03.325Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-19T23:13:03.879Z"
   },
   {
    "duration": 69,
    "start_time": "2024-12-19T23:13:03.885Z"
   },
   {
    "duration": 1992,
    "start_time": "2024-12-19T23:13:27.098Z"
   },
   {
    "duration": 1899,
    "start_time": "2024-12-19T23:13:37.055Z"
   },
   {
    "duration": 227,
    "start_time": "2024-12-19T23:14:33.247Z"
   },
   {
    "duration": 1856,
    "start_time": "2024-12-19T23:14:41.009Z"
   },
   {
    "duration": 1826,
    "start_time": "2024-12-19T23:14:42.868Z"
   },
   {
    "duration": 1026,
    "start_time": "2024-12-19T23:14:44.696Z"
   },
   {
    "duration": 28,
    "start_time": "2024-12-19T23:14:45.724Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-19T23:14:45.755Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-19T23:14:45.763Z"
   },
   {
    "duration": 578,
    "start_time": "2024-12-19T23:14:45.772Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-19T23:14:46.352Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-19T23:14:46.358Z"
   },
   {
    "duration": 20,
    "start_time": "2024-12-19T23:16:55.889Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-19T23:17:43.936Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-19T23:19:20.809Z"
   },
   {
    "duration": 233,
    "start_time": "2024-12-19T23:19:58.165Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-19T23:20:12.329Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-19T23:20:29.193Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-19T23:21:02.542Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-19T23:21:18.888Z"
   },
   {
    "duration": 240,
    "start_time": "2024-12-19T23:22:29.974Z"
   },
   {
    "duration": 1847,
    "start_time": "2024-12-19T23:23:09.797Z"
   },
   {
    "duration": 1858,
    "start_time": "2024-12-19T23:23:11.647Z"
   },
   {
    "duration": 1029,
    "start_time": "2024-12-19T23:23:13.507Z"
   },
   {
    "duration": 29,
    "start_time": "2024-12-19T23:23:14.537Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-19T23:23:14.569Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-19T23:23:14.579Z"
   },
   {
    "duration": 532,
    "start_time": "2024-12-19T23:23:14.585Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-19T23:23:15.119Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-19T23:23:15.125Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-19T23:23:15.143Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-19T23:23:15.159Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-19T23:23:15.165Z"
   },
   {
    "duration": 471,
    "start_time": "2024-12-19T23:23:15.170Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-19T23:23:35.938Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-19T23:23:37.279Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-19T23:23:37.995Z"
   },
   {
    "duration": 1087,
    "start_time": "2024-12-19T23:23:38.984Z"
   },
   {
    "duration": 136,
    "start_time": "2024-12-19T23:25:38.150Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-19T23:27:36.884Z"
   },
   {
    "duration": 143,
    "start_time": "2024-12-19T23:28:24.114Z"
   },
   {
    "duration": 154,
    "start_time": "2024-12-19T23:29:24.234Z"
   },
   {
    "duration": 159,
    "start_time": "2024-12-19T23:29:39.863Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-19T23:30:03.189Z"
   },
   {
    "duration": 142,
    "start_time": "2024-12-19T23:30:09.425Z"
   },
   {
    "duration": 21,
    "start_time": "2024-12-19T23:31:21.815Z"
   },
   {
    "duration": 24,
    "start_time": "2024-12-19T23:32:15.794Z"
   },
   {
    "duration": 20,
    "start_time": "2024-12-19T23:32:23.555Z"
   },
   {
    "duration": 15502,
    "start_time": "2024-12-19T23:33:56.319Z"
   },
   {
    "duration": 177,
    "start_time": "2024-12-19T23:34:11.823Z"
   },
   {
    "duration": 190,
    "start_time": "2024-12-19T23:34:50.790Z"
   },
   {
    "duration": 150,
    "start_time": "2024-12-19T23:35:13.228Z"
   },
   {
    "duration": 307,
    "start_time": "2024-12-19T23:35:47.704Z"
   },
   {
    "duration": 365,
    "start_time": "2024-12-19T23:35:58.935Z"
   },
   {
    "duration": 374,
    "start_time": "2024-12-19T23:36:09.210Z"
   },
   {
    "duration": 36839,
    "start_time": "2024-12-19T23:36:22.546Z"
   },
   {
    "duration": 4100,
    "start_time": "2024-12-19T23:38:09.787Z"
   },
   {
    "duration": 327,
    "start_time": "2024-12-19T23:38:18.083Z"
   },
   {
    "duration": 30,
    "start_time": "2024-12-19T23:38:35.787Z"
   },
   {
    "duration": 27,
    "start_time": "2024-12-19T23:38:44.635Z"
   },
   {
    "duration": 219,
    "start_time": "2024-12-19T23:39:02.558Z"
   },
   {
    "duration": 292,
    "start_time": "2024-12-19T23:39:17.257Z"
   },
   {
    "duration": 71572,
    "start_time": "2024-12-19T23:44:29.233Z"
   },
   {
    "duration": 14881,
    "start_time": "2024-12-19T23:46:38.837Z"
   },
   {
    "duration": 4976,
    "start_time": "2024-12-19T23:47:28.833Z"
   },
   {
    "duration": 22289,
    "start_time": "2024-12-19T23:48:46.965Z"
   },
   {
    "duration": 22192,
    "start_time": "2024-12-19T23:49:29.116Z"
   },
   {
    "duration": 78312,
    "start_time": "2024-12-19T23:49:52.497Z"
   },
   {
    "duration": 155259,
    "start_time": "2024-12-19T23:51:11.934Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-19T23:55:27.258Z"
   },
   {
    "duration": 68421,
    "start_time": "2024-12-19T23:55:35.407Z"
   },
   {
    "duration": 33271,
    "start_time": "2024-12-19T23:58:20.467Z"
   },
   {
    "duration": 30673,
    "start_time": "2024-12-19T23:59:03.824Z"
   },
   {
    "duration": 27491,
    "start_time": "2024-12-20T00:00:33.833Z"
   },
   {
    "duration": 664,
    "start_time": "2024-12-20T00:02:16.698Z"
   },
   {
    "duration": 602,
    "start_time": "2024-12-20T00:02:31.762Z"
   },
   {
    "duration": 601,
    "start_time": "2024-12-20T00:02:41.038Z"
   },
   {
    "duration": 715,
    "start_time": "2024-12-20T00:02:51.801Z"
   },
   {
    "duration": 587,
    "start_time": "2024-12-20T00:03:05.423Z"
   },
   {
    "duration": 214,
    "start_time": "2024-12-20T00:03:18.212Z"
   },
   {
    "duration": 29099,
    "start_time": "2024-12-20T00:03:39.665Z"
   },
   {
    "duration": 3362,
    "start_time": "2024-12-20T00:04:56.454Z"
   },
   {
    "duration": 3111,
    "start_time": "2024-12-20T00:05:13.598Z"
   },
   {
    "duration": 8109,
    "start_time": "2024-12-20T00:05:42.010Z"
   },
   {
    "duration": 8141,
    "start_time": "2024-12-20T01:08:07.832Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-20T01:10:17.464Z"
   },
   {
    "duration": 1015,
    "start_time": "2024-12-20T01:10:29.928Z"
   },
   {
    "duration": 7600,
    "start_time": "2024-12-20T01:12:05.847Z"
   },
   {
    "duration": 8516,
    "start_time": "2024-12-20T01:15:24.454Z"
   },
   {
    "duration": 8530,
    "start_time": "2024-12-20T01:15:34.137Z"
   },
   {
    "duration": 6021,
    "start_time": "2024-12-20T01:16:32.994Z"
   },
   {
    "duration": 890,
    "start_time": "2024-12-20T01:18:12.631Z"
   },
   {
    "duration": 1283,
    "start_time": "2024-12-20T01:20:08.542Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-20T01:21:24.059Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-20T01:21:44.349Z"
   },
   {
    "duration": 24,
    "start_time": "2024-12-20T01:22:37.171Z"
   },
   {
    "duration": 270,
    "start_time": "2024-12-20T01:22:42.859Z"
   },
   {
    "duration": 270,
    "start_time": "2024-12-20T01:23:02.004Z"
   },
   {
    "duration": 263,
    "start_time": "2024-12-20T01:23:10.353Z"
   },
   {
    "duration": 261,
    "start_time": "2024-12-20T01:23:21.733Z"
   },
   {
    "duration": 261,
    "start_time": "2024-12-20T01:23:31.078Z"
   },
   {
    "duration": 265,
    "start_time": "2024-12-20T01:23:41.443Z"
   },
   {
    "duration": 262,
    "start_time": "2024-12-20T01:23:49.767Z"
   },
   {
    "duration": 2336,
    "start_time": "2024-12-20T20:34:26.163Z"
   },
   {
    "duration": 1802,
    "start_time": "2024-12-20T20:34:28.501Z"
   },
   {
    "duration": 1003,
    "start_time": "2024-12-20T20:34:30.305Z"
   },
   {
    "duration": 30,
    "start_time": "2024-12-20T20:34:31.310Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-20T20:34:31.343Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-20T20:34:31.353Z"
   },
   {
    "duration": 510,
    "start_time": "2024-12-20T20:34:31.373Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-20T20:34:31.885Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-20T20:34:31.890Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-20T20:34:31.908Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-20T20:34:31.916Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-20T20:35:51.446Z"
   },
   {
    "duration": 1948,
    "start_time": "2024-12-21T03:10:00.513Z"
   },
   {
    "duration": 1803,
    "start_time": "2024-12-21T03:10:02.464Z"
   },
   {
    "duration": 2676,
    "start_time": "2024-12-21T03:10:04.269Z"
   },
   {
    "duration": 39,
    "start_time": "2024-12-21T03:10:06.947Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-21T03:10:06.989Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-21T03:10:06.999Z"
   },
   {
    "duration": 569,
    "start_time": "2024-12-21T03:10:07.006Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-21T03:10:07.578Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-21T03:10:07.583Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-21T03:10:07.601Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-21T03:10:07.609Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-21T03:10:07.614Z"
   },
   {
    "duration": 8980,
    "start_time": "2024-12-21T03:10:07.618Z"
   },
   {
    "duration": 1137,
    "start_time": "2024-12-21T03:10:16.602Z"
   },
   {
    "duration": 245,
    "start_time": "2024-12-21T03:10:17.742Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-21T03:10:17.989Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-21T03:10:17.990Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-21T03:10:17.991Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-21T03:10:17.992Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-21T03:10:17.994Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-21T03:10:17.995Z"
   },
   {
    "duration": 8346,
    "start_time": "2024-12-21T03:10:38.850Z"
   },
   {
    "duration": 7955,
    "start_time": "2024-12-21T03:12:41.651Z"
   },
   {
    "duration": 7093,
    "start_time": "2024-12-21T03:12:58.752Z"
   },
   {
    "duration": 6122,
    "start_time": "2024-12-21T03:13:54.540Z"
   },
   {
    "duration": 876,
    "start_time": "2024-12-21T03:16:04.180Z"
   },
   {
    "duration": 118,
    "start_time": "2024-12-21T03:17:21.740Z"
   },
   {
    "duration": 257,
    "start_time": "2024-12-21T03:20:09.990Z"
   },
   {
    "duration": 185,
    "start_time": "2024-12-21T03:20:19.504Z"
   },
   {
    "duration": 1280,
    "start_time": "2024-12-21T03:20:31.738Z"
   },
   {
    "duration": 140,
    "start_time": "2024-12-21T03:21:10.836Z"
   },
   {
    "duration": 134,
    "start_time": "2024-12-21T03:21:22.218Z"
   },
   {
    "duration": 122,
    "start_time": "2024-12-21T03:21:33.359Z"
   },
   {
    "duration": 1148,
    "start_time": "2024-12-21T03:21:51.384Z"
   },
   {
    "duration": 132,
    "start_time": "2024-12-21T03:22:31.999Z"
   },
   {
    "duration": 127,
    "start_time": "2024-12-21T03:22:39.278Z"
   },
   {
    "duration": 127,
    "start_time": "2024-12-21T03:22:46.423Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

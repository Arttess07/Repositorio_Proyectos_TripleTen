{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Análisis de comportamiento de los usuarios de Megaline.\n",
    "\n",
    "En este análisis vamos a explorar el comportamiento de los usuarios de la compañía Megaline.\n",
    "Lo que buscamos lograr es conocer cuales usuarios están migrando de plan de servicio.\n",
    "Queremos que menos usuarios usen planes heredados y mejor migren a uno de los dos planes contemporáneos: Smart o Ultra.\n",
    "Vamos a usar la data disponible para estudiar el comportamiento del usuario y poder ofrecer al perfil adecuado el plan ideal según su comportamiento.\n",
    "En eset caso estamos hablando de un problemas de clasificación de data, así que usaremos modelos de clasificación para este análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   int64  \n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   int64  \n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('users_behavior.csv') #Leer base de datos\n",
    "\n",
    "print(df.info()) #Revisar información disponible\n",
    "print()\n",
    "\n",
    "df['calls'] = df['calls'].astype('int64') #Cambiamos el tipo de dato a los datos correctos para trabajar con ellos\n",
    "df['messages'] = df['messages'].astype('int64')\n",
    "\n",
    "print(df.info()) #Comprobamos el cambio\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El total de duplicados es de: 0\n",
      "\n",
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"El total de duplicados es de: {df.duplicated().sum()}\") #Revisamos duplicados\n",
    "print()\n",
    "print(df.isna().sum()) #Revisamos datos nulos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Segmentación de la información para entrenar el modelo\n",
    "\n",
    "Ahora que revisamos la información disponible y limpiamos la base, ya la podemos usar para el análisis.\n",
    "En esta siguiente seccion vamos a dividir la data para el entrenamiento y prueba.\n",
    "También en este paso crearemos un dataset de validación, características y objetivo de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn #Instalar librería para poder usar funciones de machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split #Importar fórmula para dividir la data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data  = train_test_split(df, test_size=0.20, random_state=12345) #Dividimos la data em dos para entrenar el modelo. Usamos un modelo 80/20 para la compración de datos. 80%  de entrenamiento, 20% para laa pruebas.\n",
    "train_data_val, validation_data = train_test_split(train_data, test_size=0.25) #Dividimos la data de entrenamiento para poder tener un data set de validación del modelo entrenado.\n",
    "\n",
    "features_train = train_data_val.drop(['is_ultra'], axis=1) #Indicamos las características a entrenar\n",
    "value_train = train_data_val['is_ultra'] #Indicamos el objetivo que buscamos con el modelo\n",
    "\n",
    "features_test = test_data.drop(['is_ultra'], axis=1) #Indicamos las características a probar\n",
    "value_test = test_data['is_ultra'] #Indicamos las características a probar\n",
    "\n",
    "features_val = validation_data.drop(['is_ultra'], axis=1) #Indicamos características de validación\n",
    "value_val = validation_data['is_ultra'] #Indicamos objetivos de validación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Crear modelos de predicción usando modelos de decisiones para clasificación.\n",
    "\n",
    "Ya que tenemos la data lista para ser usada, ahora vamos a usar diferentes modelos de predicción para la clasificación de los planes.\n",
    "En este segmento buscamos validar cual es el mejore modelo de clasificación que debmos usar para este ejercicio.\n",
    "Usaremos un árbol de decisión y un bosque de decisión para realizar las clasifiaciones-\n",
    "Aunque vayamos a usar modelos de clasificación, vale la pena usar un modelo de regresión logística para los modelos.\n",
    "Este modelo de regrsión también nos puede indicar a que usuarios serían más viable recomendar el plan que más se asemeje a su tipo de consumo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento:  1.0\n",
      "Validación:  0.7278382581648523\n",
      "Prueba:  0.687402799377916\n"
     ]
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier(random_state=12345)\n",
    "tree_model.fit(features_train, value_train)\n",
    "print(\"Entrenamiento: \", tree_model.score(features_train, value_train)) #Aqui validamos la exactitud del bosque\n",
    "print(\"Validación: \", tree_model.score(features_val, value_val))\n",
    "print(\"Prueba: \", tree_model.score(features_test, value_test)) #Usar un árbol decisión para este problema no es eficiente, necesitamos un modelo más robusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier #Importamos modelo para el bosque de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de árboles: 1\n",
      "Entrenamiento:  0.9087136929460581\n",
      "Validación:  0.7371695178849145\n",
      "Prueba:  0.7060653188180405\n",
      "\n",
      "Cantidad de árboles: 2\n",
      "Entrenamiento:  0.9056016597510373\n",
      "Validación:  0.7698289269051322\n",
      "Prueba:  0.7325038880248833\n",
      "\n",
      "Cantidad de árboles: 3\n",
      "Entrenamiento:  0.9470954356846473\n",
      "Validación:  0.7651632970451011\n",
      "Prueba:  0.749611197511664\n",
      "\n",
      "Cantidad de árboles: 4\n",
      "Entrenamiento:  0.946058091286307\n",
      "Validación:  0.7713841368584758\n",
      "Prueba:  0.7620528771384136\n",
      "\n",
      "Cantidad de árboles: 5\n",
      "Entrenamiento:  0.9683609958506224\n",
      "Validación:  0.7838258164852255\n",
      "Prueba:  0.7527216174183515\n",
      "\n",
      "Cantidad de árboles: 6\n",
      "Entrenamiento:  0.9642116182572614\n",
      "Validación:  0.7884914463452566\n",
      "Prueba:  0.7744945567651633\n",
      "\n",
      "Cantidad de árboles: 7\n",
      "Entrenamiento:  0.9761410788381742\n",
      "Validación:  0.8009331259720062\n",
      "Prueba:  0.776049766718507\n",
      "\n",
      "Cantidad de árboles: 8\n",
      "Entrenamiento:  0.9735477178423236\n",
      "Validación:  0.7884914463452566\n",
      "Prueba:  0.7776049766718507\n",
      "\n",
      "Cantidad de árboles: 9\n",
      "Entrenamiento:  0.9839211618257261\n",
      "Validación:  0.7869362363919129\n",
      "Prueba:  0.7838258164852255\n",
      "\n",
      "Cantidad de árboles: 10\n",
      "Entrenamiento:  0.979253112033195\n",
      "Validación:  0.7978227060653188\n",
      "Prueba:  0.7931570762052877\n",
      "\n",
      "Cantidad de árboles: 11\n",
      "Entrenamiento:  0.9854771784232366\n",
      "Validación:  0.8009331259720062\n",
      "Prueba:  0.7853810264385692\n",
      "\n",
      "Cantidad de árboles: 12\n",
      "Entrenamiento:  0.9844398340248963\n",
      "Validación:  0.8009331259720062\n",
      "Prueba:  0.7869362363919129\n",
      "\n",
      "Cantidad de árboles: 13\n",
      "Entrenamiento:  0.9885892116182573\n",
      "Validación:  0.8040435458786936\n",
      "Prueba:  0.7853810264385692\n",
      "\n",
      "Cantidad de árboles: 14\n",
      "Entrenamiento:  0.9849585062240664\n",
      "Validación:  0.80248833592535\n",
      "Prueba:  0.7869362363919129\n",
      "\n",
      "Cantidad de árboles: 15\n",
      "Entrenamiento:  0.9880705394190872\n",
      "Validación:  0.8040435458786936\n",
      "Prueba:  0.7884914463452566\n",
      "\n",
      "Cantidad de árboles: 16\n",
      "Entrenamiento:  0.9849585062240664\n",
      "Validación:  0.8055987558320373\n",
      "Prueba:  0.7853810264385692\n",
      "\n",
      "Cantidad de árboles: 17\n",
      "Entrenamiento:  0.9896265560165975\n",
      "Validación:  0.8009331259720062\n",
      "Prueba:  0.7838258164852255\n",
      "\n",
      "Cantidad de árboles: 18\n",
      "Entrenamiento:  0.9865145228215768\n",
      "Validación:  0.8040435458786936\n",
      "Prueba:  0.7822706065318819\n",
      "\n",
      "Cantidad de árboles: 19\n",
      "Entrenamiento:  0.9911825726141079\n",
      "Validación:  0.8055987558320373\n",
      "Prueba:  0.7853810264385692\n",
      "\n",
      "Cantidad de árboles: 20\n",
      "Entrenamiento:  0.9885892116182573\n",
      "Validación:  0.8055987558320373\n",
      "Prueba:  0.7869362363919129\n",
      "\n",
      "Cantidad de árboles: 21\n",
      "Entrenamiento:  0.9932572614107884\n",
      "Validación:  0.7993779160186625\n",
      "Prueba:  0.7853810264385692\n",
      "\n",
      "Cantidad de árboles: 22\n",
      "Entrenamiento:  0.9896265560165975\n",
      "Validación:  0.8040435458786936\n",
      "Prueba:  0.7869362363919129\n",
      "\n",
      "Cantidad de árboles: 23\n",
      "Entrenamiento:  0.9968879668049793\n",
      "Validación:  0.807153965785381\n",
      "Prueba:  0.7853810264385692\n",
      "\n",
      "Cantidad de árboles: 24\n",
      "Entrenamiento:  0.9932572614107884\n",
      "Validación:  0.8087091757387247\n",
      "Prueba:  0.7838258164852255\n",
      "\n",
      "Cantidad de árboles: 25\n",
      "Entrenamiento:  0.9963692946058091\n",
      "Validación:  0.8087091757387247\n",
      "Prueba:  0.7822706065318819\n",
      "\n",
      "Cantidad de árboles: 26\n",
      "Entrenamiento:  0.9937759336099585\n",
      "Validación:  0.8102643856920684\n",
      "Prueba:  0.7838258164852255\n",
      "\n",
      "Cantidad de árboles: 27\n",
      "Entrenamiento:  0.9968879668049793\n",
      "Validación:  0.8102643856920684\n",
      "Prueba:  0.7853810264385692\n",
      "\n",
      "Cantidad de árboles: 28\n",
      "Entrenamiento:  0.9953319502074689\n",
      "Validación:  0.8102643856920684\n",
      "Prueba:  0.7916018662519441\n",
      "\n",
      "Cantidad de árboles: 29\n",
      "Entrenamiento:  0.9963692946058091\n",
      "Validación:  0.807153965785381\n",
      "Prueba:  0.7853810264385692\n",
      "\n",
      "Cantidad de árboles: 30\n",
      "Entrenamiento:  0.9963692946058091\n",
      "Validación:  0.8133748055987559\n",
      "Prueba:  0.7853810264385692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for trees in range (1,31): \n",
    "    forest_model = RandomForestClassifier(n_estimators=trees, random_state=12345) #Almacenamos nuestro modelo e indicamos un estado de azar, también definimos la cantidad de arboles dentro de nuestro bosque\n",
    "    forest_model.fit(features_train, value_train) #Creamos nuestro modelo entrenado para Bosque de Decisiones\n",
    "    print(\"Cantidad de árboles:\", trees)\n",
    "    print(\"Entrenamiento: \", forest_model.score(features_train, value_train)) #Aqui validamos la exactitud del bosque\n",
    "    print(\"Validación: \", forest_model.score(features_val, value_val))\n",
    "    print(\"Prueba: \", forest_model.score(features_test, value_test))\n",
    "    print()\n",
    "    #Creamos un for para poder conocer cuántos árboles me van a brindar la validación más alta de mi modelo.\n",
    "    #En este caso tener 28 árboles dentro del modelo nos dá la validación más alta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de árboles: 28\n",
      "Entrenamiento:  0.9953319502074689\n",
      "Validación:  0.8102643856920684\n",
      "Prueba:  0.7916018662519441\n"
     ]
    }
   ],
   "source": [
    "forest_model = RandomForestClassifier(n_estimators=28, random_state=12345) \n",
    "forest_model.fit(features_train, value_train) \n",
    "print(\"Cantidad de árboles:\", 28)\n",
    "print(\"Entrenamiento: \", forest_model.score(features_train, value_train))\n",
    "print(\"Validación: \", forest_model.score(features_val, value_val))\n",
    "print(\"Prueba: \", forest_model.score(features_test, value_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression #Importamos los modelos que usaremos para realizar las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento:  0.7551867219917012\n",
      "Validación:  0.7309486780715396\n",
      "Prueba:  0.7589424572317263\n"
     ]
    }
   ],
   "source": [
    "linear_model = LogisticRegression(random_state=12345) #Almacenamos nuestro modelo para ser usado e indicamos un estado de azar\n",
    "linear_model.fit(features_train, value_train) #Creamos nuestro modelo de entrenamiento para Regresión Linear\n",
    "print(\"Entrenamiento: \", linear_model.score(features_train, value_train)) #Aqui validamos la exactitud del modelo linear\n",
    "print(\"Validación: \", linear_model.score(features_val, value_val)) \n",
    "print(\"Prueba: \", linear_model.score(features_test, value_test)) #Aunque este modelo se acerca a nuestro objetivo, la validación es menor al 0.75 que buscamos.\n",
    "#Será mejor tomar algún modelo anterior para realizar la predicción. Aunque este modelo sea fácil de utilizar y ahorre recursos, en este caso no es el ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Conclusiones\n",
    "\n",
    "En este caso lo mejor sería un bosque de decisición para la clasificación de los datos.\n",
    "Este modelo es más robusto y cumple con nuestro estándar de exactitud para la predicción.\n",
    "Este modelo usa varios árboles de decisiones y compara los resultados para llegar a la mejor exactitud.\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 792,
    "start_time": "2024-10-01T01:17:49.775Z"
   },
   {
    "duration": 58,
    "start_time": "2024-10-01T01:18:13.234Z"
   }
  ],
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
